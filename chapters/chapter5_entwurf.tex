% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %% Kapitel 5 - Entwurf %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Effizienz und Effektivität in der multivariaten Versuchsplanung} \label{chap:entwurf}

Nach der in Kapitel~\ref{chap:screening} beschriebenen qualitativen Vorselektion der Einflussgrößen ist nun die quantitative Planung durch die Entwicklung adäquater, effizienter und multivariater Versuchspläne erforderlich.
Ziel ist es, etablierte Standard-\acp{RSD} gezielt an die spezifischen Anforderungen der Lebensdauerprognose anzupassen, ohne deren statistische Integrität unzulässig zu kompromittieren.
In Anlehnung an die Ausführungen aus Abschnitt~\ref{sec:forschungsfragen} gilt dabei fortwährend die Prämisse, dass insbesondere das \ac{CCD} aufgrund seiner sequenziellen Augmentierbarkeit (Screening $\to$ lineares Modell $\to$ quadratische Modellterme, vgl. Abbildung~\ref{fig:abb2.08_strategy}) im Kontext kostenintensiver \ac{EoL}-Tests einen entscheidenden operativen Vorzug bietet und daher im Fokus der vorliegenden Untersuchung steht.

Dieses Kapitel widmet sich  in zwei Schritten zunächst der systematischen Analyse geometrischer Design-Abweichungen und deren Auswirkung auf die statistische Güte (siehe Abschnitt~\ref{sec:abweichungen}).
Unabhängig von einer möglichen Beschleunigung durch \ac{ALT} wird zuerst untersucht, inwieweit typische Manipulationen der Design-Geometrie wie variierende Koordinaten oder asymmetrische Replikationen der Versuchspunkte sowie mangelnde Robustheit in der Versuchssteuerung die Performance beeinflussen.
Um diese komplexen Abhängigkeiten generisch und losgelöst von spezifischen Produktdaten zu untersuchen, ist der Einsatz numerischer Simulationen immer dann erforderlich, wenn die Parameterschätzung betreffende Metriken erfasst werden sollen.
Mithilfe von \acp{MCS} und fiktiven physikalischen Modellen wird die Entwicklung dieser Verhältnismäßigkeiten somit systematisch aufgezeigt, siehe Abschnitt~\ref{subsec:simulationsmethodik}.
In einem zweiten Schritt werden daraus als signifikant erfasste Einflüsse durch Design-Modifikationen hinsichtlich ihrer generischen Auswirkung auf die Modellierung bewertet (Abschnitt~\ref{subsec:sensitivitaetsanalyse}).
Sie sollen im weiteren Verlauf der Untersuchung als Grundlage für die Auswahl vielversprechender Design-Alternativen dienen, die im Anschluss ökonomisch bewertet werden.
Um hierbei valide Aussagen über die \textbf{Effektivität} einer Konfiguration zu treffen, wird neben der bloßen Versuchsplan-Performance oder Schätzgüte die \textbf{statistische Trennschärfe (\ac{power})} als übergeordnete Metrik herangezogen.
Sie fungiert als Indikator für die Erfolgsgarantie der Testagenda, indem sie die Wahrscheinlichkeit beziffert, mit der real existierende Effekte tatsächlich mithilfe des jeweiligen Versuchsplans als signifikant erkannt werden, vgl. Abschnitt~\ref{subsec:optimal}.
Was in der allgemeinen \ac{DoE}-Methodik oft als nachgeordnete Größe behandelt wird \cite{Rigdon.2022,Montgomery.2020}, avanciert bei kostenintensiven \ac{EoL}-Tests zum \ac{KPI}: Jede Manipulation des Designs muss zwingend gegen den potenziellen Verlust an der Detektionswahrscheinlichkeit hinsichtlich der Effekte auf die Lebensdauer innerhalb des \ac{GLM} abgewogen werden (entsprechend Abschnitt~\ref{subsec:orthogonalitaetsabweichungen}).

Darauf aufbauend führt Abschnitt~\ref{sec:kostenmodell} ein Kostenmodell ein, um außerdem die monetären Konsequenzen derartiger Modifikationen zu quantifizieren.
Die Bewertung der Versuchspläne erfolgt dabei streng nach der Kerndefinition von \textbf{Effizienz} als Maß für die Leistungsfähigkeit: Welche Information wird perspektivisch generiert und welcher monetäre Aufwand steht dem gegenüber?
Daraus leitet sich die zentrale ökonomische Leitfrage ab: \textit{Wie viel Trennschärfe ist finanzierbar?}
Erst so wird quantifiziert, inwiefern zufällige oder möglicherweise bewusste Design-Modifikationen die Effizienz des \ac{RSD} verändern und zu welchem Maß die Effektivität dabei beeinträchtigt wird.

Zur Bewertung der Prognosegüte wird abschließend eine Erweiterung bestehender Visualisierungsmethoden vorgestellt (Abschnitt~\ref{sec:visualisierung}), bevor die Gesamtmethodik in der numerischen Simulationsstudie anhand der Zuverlässigkeitsmodellierung mit Aussagesicherheit final bewertet wird (Abschnitt~\ref{sec:zuv_vb}).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Analyse generischer Design-Abweichungen} \label{sec:abweichungen}
Die Versuchsplanung für die Zuverlässigkeitstechnik kann aus praktischen Gründen abweichen vom idealen Lehrbuch-Design.
Ursachen hierfür können physikalische Restriktionen des Prüfstands, die spezifische Performance des Systems prinzipiell oder bei \ac{ALT} oder eine bewusste Manipulation des Versuchsraums zur Steigerung der Extrapolationsgüte sein.
Insbesondere im Kontext der Lebensdauerprognose sind solche Eingriffe praxisrelevant und begründet: Die Verschiebung der Versuchspunkte in Richtung höherer Lastniveaus verkürzt die Prüfzeit und senkt die Kosten, während eine Verortung nahe dem Operationsbereich die Modellanpassung verbessert und die Extrapolationsunsicherheit reduziert.

Allerdings bergen solche Modifikationen das Risiko, die statistische Integrität des Designs zu beeinträchtigen.
Im Idealfall sind die Design-Matrix-Spalten eines \ac{CCD} orthogonal zueinander, was eine unabhängige Schätzung der Modellparameter ermöglicht (vgl. Abschnitt~\ref{subsubsec:rsm}).
Geometrische Verzerrungen führen zwangsläufig zu einem Verlust dieser Orthogonalität (vgl. Gleichung~\ref{eq:skalar}).
Besonders kritisch ist, dass die Auswirkungen peripherer Parameterstufen (Sternpunkte) oft erst spät im sequenziellen Prozess sichtbar werden - nämlich dann, wenn das initiale faktorielle Design erweitert wird.
Daher ist es essenziell, die Robustheit des \ac{CCD} gegenüber typischen Design-Abweichungen systematisch zu quantifizieren.
Entgegen vergleichbarer Untersuchungen durch \textcite{Box.1963, Ahn.2015,Donev.2004,Zhang.2021} oder vergleichbarer liegt der Fokus hier nicht auf der reinen geometrischen Verzerrung, sondern auf der quantitativen Bewertung der Auswirkungen auf die Schätzpräzision und insbesondere die Trennschärfe im Kontext von Lebensdauerprognosen, was eine stochastische Simulation mit einem pseudo-physikalischen Modell erforderlich macht.

\subsection{Methodik der stochastischen Simulation und Modellbildung} \label{subsec:simulationsmethodik}
Um die Auswirkungen von Design-Abweichungen auf die statistische Güte quantifizieren zu können, bedarf es einer kontrollierten Untersuchungsumgebung, in der - im Gegensatz zu physischen Experimenten - die \textit{wahre} Natur des Systems bekannt ist.
Nur durch den Vergleich der Analyseergebnisse mit einer vorab definierten Wahrheit (engl. \textbf{Ground Truth}) lassen sich Metriken wie die Schätzpräzision und hauptsächlich die \ac{power} valide bestimmen.
Zu diesem Zweck wird eine Simulationsumgebung geschaffen, die auf einem scheinbar-physikalischen Modell basiert.\\

\textbf{Pseudo-physikalisches Simulationsmodell} \\
Das zugrundeliegende Systemverhalten wird durch ein polynomiales Regressionsmodell zweiter Ordnung approximiert.
Dies entspricht der Struktur, die auch als Ergebnis der \ac{RSM}-Untersuchung erwartet wird (vgl. Gleichung~\ref{eq:quadric_std_model}).
Um die Anforderungen an eine multivariate Untersuchung ($\sym{k} \ge 2$) zu erfüllen und die Komplexität handhabbar zu halten, wird im Basisszenario von zwei Faktoren ($\sym{x}_1, \sym{x}_2$) ausgegangen.
Das Modell berücksichtigt neben den Haupteffekten explizit die für die Lebensdaueranalyse kritischen Wechselwirkungen ersten Grades sowie quadratische Terme zur Abbildung von Nichtlinearitäten:
\begin{equation} \label{eq:simulation_model}
    \sym{y}_{\sym{idx_sim}} = \sym{beta}_{0} + \sym{beta}_{1}\sym{x}_{1} + \sym{beta}_{2}\sym{x}_{2} + \sym{beta}_{12}\sym{x}_{1}\sym{x}_{2} + \sym{beta}_{11}\sym{x}_{1}^2 + \sym{beta}_{22}\sym{x}_{2}^2 + \sym{epsilon}.
\end{equation}

Um ein realistisches, stochastisches Verhalten abzubilden, sind die Modellparameter nicht deterministisch fixiert.
Den Regressionskoeffizienten $\symsub{beta}{idx_j}$ werden zwar nominale Startwerte zugewiesen (vgl. Tabelle~\ref{tab:simulation_parameters}), diese werden jedoch in jedem Simulationslauf mit einer definierten Streuung überlagert.
Zusätzlich wird die resultierende Systemantwort $\sym{y}_{\sym{idx_sim}}$ mit einer Reststreuung $\sym{epsilon}$ beaufschlagt, um die inhärente aleatorische Unsicherheit des Systems (Messfehler, unbekannte Einflüsse) abzubilden.
Die Default-Werte für die Koeffizienten sowie die vorgegebene Standardabweichung $\sym{sigma}_{\sym{idx_sim}}$, welche als Streuparameter für das stochastische Basis-Verhalten dient, sind in Tabelle~\ref{tab:simulation_parameters} zusammengefasst.

\begin{table}[htbp]
    \centering
    \caption{Nominale Startwerte und Streuparameter des pseudo-physikalischen Simulationsmodells}
    \label{tab:simulation_parameters}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Modellparameter}                                                           & \textbf{Default-Wert} \\
        \midrule
        Regressionskonstante $\sym{beta}_{0}$                                              & $30$                  \\
        Regressionskoeffizienten $\symsub{beta}{idx_j}$ (für $j \in \{1, 2, 12, 11, 22\}$) & $10$                  \\
        Standardabweichung der Systemantwort $\symsub{sigma}{idx_sim}$                     & $1$                   \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Simulationsalgorithmus und Monte-Carlo-Ansatz} \\
Dieses Modell wird mit den zu untersuchenden Versuchsplänen gekoppelt.
Für jeden Stützpunkt des Versuchsplans werden die korrespondierenden Systemantworten simuliert.
Anschließend erfolgt die Rückrechnung des Regressionsmodells mittels \ac{MLE}, entsprechend der ausgeführten Methodik aus Abschnitt~\ref{subsubsec:mle}.
Um statistisch belastbare Aussagen zu treffen, wird das Verfahren in eine \ac{MCS} mit $\symsub{n}{idx_MC} = 10.000$ Iterationen eingebettet.
Dieser Ansatz erlaubt die Bewertung zweier zentraler Kriterien:
\begin{enumerate}
    \item \textbf{Präzision der Parameterschätzung:} Durch den Vergleich der geschätzten Parameter $\hat{\sym{beta}}$ mit den „wahren“ Koeffizienten $\sym{beta}_{\text{true}}$ lassen sich Bias und Varianz der Schätzung ermitteln.
    \item \textbf{Bestimmung der Trennschärfe (Power):} Für jeden Simulationslauf wird geprüft, ob die signifikanten Effekte korrekt erkannt wurden ($\sym{p-Wert} < \sym{alpha}$). Das Verhältnis der Treffer zur Gesamtzahl der Simulationen ergibt die empirische \ac{power} (vgl. Gleichung~\ref{eq:power}).
\end{enumerate}

\subsection{Sensitivitätsanalyse geometrischer und stochastischer Einflussgrößen} \label{subsec:sensitivitaetsanalyse}
Um die Robustheit des \ac{CCD} gegenüber den eingangs erwähnten Abweichungen quantitativ zu bewerten, wurde eine umfassende Simulationsstudie durchgeführt.
Der methodische Ansatz folgt einem \textit{Design of Experiments on Experiments}-Konzept: Die Eigenschaften des Versuchsplans sowie der Systemantwort werden als Faktoren eines übergeordneten Meta-Designs variiert.
Im Gegensatz zu reinen Screening-Ansätzen kam hierfür ein **Zentral-Zusammengesetzter Versuchsplan (CCD) mit Blockbildung** zum Einsatz.
Dies ermöglichte nicht nur die Identifikation linearer Haupteffekte, sondern auch die Analyse nicht-linearer Einflüsse der Störgrößen auf die Performance-Metriken.

In der Untersuchung wurden acht Faktoren (a bis h) definiert, die sowohl deterministische geometrische Manipulationen als auch stochastische Störgrößen abbilden:
\begin{itemize}
    \item \textbf{Faktor a (Sternpunkt-Abstand $\alpha$):} Variation des Abstands der Sternpunkte zum Zentrum (z.\,B. flächenzentriert vs. rotierbar).
    \item \textbf{Faktor b (Sternpunkt-Shift):} Asymmetrische Verschiebung eines Sternpunkts zur Simulation geometrischer Verzerrungen.
    \item \textbf{Faktor c (Zentralpunkte):} Variation der Anzahl der Zentralpunkte.
    \item \textbf{Faktor d (Sternpunkte):} Variation durch das Weglassen von Sternpunkten (z.\,B. durch Ausfall).
    \item \textbf{Faktor e (System-Rauschen):} Verhältnis zwischen Modellkoeffizient und Systemabweichung.
    \item \textbf{Faktor f (Effekt-Verhältnis):} Verhältnis zweier Haupteffekte zueinander.
    \item \textbf{Faktor g (Mess-Rauschen):} Verhältnis zwischen Modellkoeffizient und Messfehler.
    \item \textbf{Faktor h (Signifikanzniveau):} Das gewählte $\alpha$-Niveau für den Hypothesentest.
\end{itemize}

Die Auswertung der Simulationsergebnisse offenbart eine signifikante Dichotomie in der Sensitivität der Zielgrößen.
Hinsichtlich der **statistischen Power** dominieren eindeutig die stochastischen und methodischen Faktoren.
Insbesondere Faktor **g** (Messfehler) und Faktor **h** (Signifikanzniveau) sowie Faktor **e** (Systemfehler) weisen die stärksten Effekte auf.
Die geometrischen Design-Faktoren (**a, b, c**) zeigten im untersuchten Bereich einen vergleichsweise geringen Einfluss auf die Power.
Selbst die Reduktion der Sternpunkte (Faktor **d**) führte nicht zwangsläufig zu einem kritischen Einbruch der Trennschärfe, solange das Rauschen kontrolliert blieb.

Bezüglich der **Schätzgüte** gewinnen die geometrischen Faktoren jedoch an Bedeutung.
Hier konnte nachgewiesen werden, dass insbesondere die Anzahl der Zentralpunkte (Faktor **c**) einen nicht-linearen Einfluss auf die Schätzung quadratischer Modellterme hat.
Auch Interaktionen zwischen geometrischen Faktoren (z.\,B. **a** und **b**) traten deutlicher hervor.

Zusammenfassend lässt die Studie den Schluss zu, dass das \ac{CCD} eine hohe Robustheit bezüglich der reinen Effektdetektion (Power) aufweist, selbst bei moderaten geometrischen Abweichungen.
Die Präzision der Modellierung reagiert jedoch sensibler auf Eingriffe.
Für die Praxis bedeutet dies: Anpassungen an \ac{ALT}-Restriktionen sind vertretbar, wenn das primäre Ziel der Nachweis eines Effekts ist; für präzise Prognosemodelle ist die geometrische Integrität jedoch strikter zu wahren.



\subsection{Fazit zu Orthogonalitäts-Abweichungen im CCD} \label{subsec:orthogonalitaetsabweichungen}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Ökonomische Bewertung: Das Kostenmodell} \label{sec:kostenmodell}
Eine rein statistische Bewertung greift in der industriellen Praxis zu kurz.
Eine Design-Modifikation, die die Prädiktionsvarianz um 5\% senkt, aber die Versuchskosten verdoppelt, ist ineffizient.
Daher wird ein Kostenmodell eingeführt, das die monetären Aufwände eines Lebensdauerversuchs in Abhängigkeit der Design-Parameter abbildet.
Die Gesamtkosten $\symsub{C}{idx_total}$ setzen sich additiv aus fixen und variablen Anteilen zusammen:
\begin{equation} \label{eq:kostenmodell}
    \symsub{C}{idx_total} = \symsub{C}{idx_fix} + \left( \sym{n} \cdot \symsub{C}{idx_spec} \right) + \left( \sum_{\sym{idx_i}=1}^{\sym{n}} \symsub{t}{idx_test}_{\sym{idx_i}}(\symsub{x}{idx_i}) \cdot \symsub{C}{idx_time} \right) + \symsub{C}{idx_fail}.
\end{equation}
Hierbei beschreibt $\symsub{C}{idx_fix}$ die Rüstkosten, $\symsub{C}{idx_spec}$ die Herstellkosten pro Prüfling und $\symsub{C}{idx_time}$ die laufenden Betriebskosten des Prüfstands pro Zeiteinheit.
Der Term $\symsub{t}{idx_test}_{\sym{idx_i}}(\symsub{x}{idx_i})$ ist die entscheidende, vom Versuchsplan abhängige Größe: Durch \ac{ALT} (hohe Lastniveaus $\sym{x}$) sinkt die Prüfzeit, was $\symsub{C}{idx_total}$ reduziert.
Gleichzeitig steigt jedoch durch aggressive Lasten potenziell der Energiebedarf oder das Risiko nicht-repräsentativer Ausfallmechanismen ($\symsub{C}{idx_fail}$).
Dieses Modell ermöglicht es, Design-Alternativen nicht nur nach ihrer statistischen Effizienz (D-, G-Effizienz), sondern nach ihrer \textit{ökonomischen Effizienz} (Information pro Euro) zu bewerten.
Dieses Modell ermöglicht es, Design-Alternativen nicht nur nach ihrer statistischen Effizienz (D-, G-Effizienz), sondern nach ihrer \textit{ökonomischen Effizienz} (Information pro Euro) zu bewerten.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Orthogonalitäts-Abweichungen in der Zuverlässigkeitsprognose} \label{sec:design_alternativen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Extrapolation Variance Graph (EVG)} \label{sec:visualisierung}
Zur Beurteilung der Vorhersagegüte im gesamten Versuchsraum haben sich der \textbf{\ac{VDG}} und der \textbf{\ac{FDS}-Plot} etabliert.
Diese Metriken bewerten die Verteilung der skalierten Prädiktionsvarianz (\ac{SPV}) jedoch oft global oder über sphärische Distanzen gemittelt.
Für die Lebensdauerprognose, bei der oft eine Extrapolation in einen spezifischen, eng begrenzten Anwendungsbereich ("Corner Case") von Interesse ist, sind diese globalen Maße oft unzureichend.

Daher wird in dieser Arbeit eine neue, erweiterte Auswertungsmethode vorgestellt: Das \textbf{Extrapolations-spezifische SPV-Mapping}.
Im Gegensatz zum klassischen VDG, der die Varianz über Radien mittelt, visualisiert diese Methode die Isolinien der Prädiktionsvarianz explizit in Richtung der relevanten Belastungsvektoren.
Dies ermöglicht die gezielte Bewertung der Design-Güte exakt in jenen Bereichen des Parameterraums, in denen die spätere Feldprognose erfolgen soll, und deckt Schwachstellen auf, die in globalen FDS-Plots verborgen blieben.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Zuverlässigkeitsmodellierung mit Vertrauensbereichen} \label{sec:zuv_vb}


\section{Simulative Validierung und Methodennachweis} \label{sec:simulation}
Aufgrund der unendlichen Kombinationsmöglichkeiten von Einflussfaktoren, Lastniveaus und physikalischen Modellen ist eine generische Sensitivitätsanalyse für alle denkbaren Anwendungsfälle nicht zielführend.
Stattdessen wird die Anwendbarkeit und Leistungsfähigkeit der vorgeschlagenen Methodik am Beispiel eines generischen Referenzsystems mittels Monte-Carlo-Simulation (MC) nachgewiesen.

\subsection{Simulationssetup}
Als Referenzsystem dient ein Weibull-verteiltes System ($\sym{b}=2, \sym{T}=1000\,\text{h}$), dessen Lebensdauerverhalten durch ein log-lineares Modell mit zwei Hauptfaktoren und einer Wechselwirkung beschrieben wird.
Im Rahmen der MC-Simulation werden $\symsub{n}{idx_MC} = 10.000$ virtuelle Versuchsreihen erzeugt, wobei für jeden Lauf:
1.  Lebensdauerdaten basierend auf dem definierten Modell und den Versuchsplan-Stützstellen (modifiziertes CCD vs. Benchmark-CCD) generiert werden.
2.  Eine stochastische Streuung sowie Zensierung (Typ I/II) aufgeprägt wird.
3.  Die Modellparameter mittels \ac{MLE} zurückgeschätzt werden.

\subsection{Ergebnisse und Effizienzbewertung}
Die Auswertung erfolgt multidimensional anhand der in den vorangegangenen Abschnitten definierten Metriken:
\begin{itemize}
    \item \textbf{Power:} Wie hoch ist die Wahrscheinlichkeit, die definierten Effekte trotz Design-Manipulation korrekt zu detektieren?
    \item \textbf{Parameterschätzgüte:} Wie verhalten sich Bias und Varianz der Schätzer ($\hat{\sym{b}}, \hat{\sym{T}}$) bei Verlust der Orthogonalität?
    \item \textbf{Ökonomische Bilanz:} Welches Design liefert die geforderte Präzision bei minimalen Gesamtkosten gemäß Gleichung~\ref{eq:kostenmodell}?
\end{itemize}
Durch den Vergleich der gesampleten Versuchszeiten (Time-to-Failure) kann valide auf die Effizienz im \ac{ALT}-Kontext geschlossen werden.
Es wird gezeigt, dass ein gezielt manipuliertes CCD, bei dem Sternpunkte in Richtung der Hauptbelastung verschoben werden, die Prognoseunsicherheit im Anwendungsbereich signifikant senken kann, ohne die maximale Versuchsanzahl oder das Budget des konventionellen Benchmarks zu überschreiten.
Damit wird der Nachweis erbracht, dass die entwickelte Methodik zur Bewertung und Anpassung von Versuchsplänen (Kostenmodell + SPV-Visualisierung + Orthogonalitäts-Check) ein robustes Werkzeug zur Steigerung der Testeffizienz darstellt.