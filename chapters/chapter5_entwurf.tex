%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Kapitel 5 - Entwurf %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Effizienz und Effektivität in der multivariaten Versuchsplanung} \label{chap:entwurf}

Nach der in Kapitel~\ref{chap:screening} beschriebenen qualitativen Vorselektion der Einflussgrößen ist nun die quantitative Planung durch Entwicklung adäquater, effizienter und multivariater Versuchspläne erforderlich.
So sollen etablierte Standard-\acp{RSD} gezielt an die Anforderungen der Lebensdauerprognose angepasst werden, ohne deren statistische Integrität unzulässig zu kompromittieren.
In Anlehnung an die Ausführungen aus Abschnitt~\ref{sec:forschungsfragen} gilt damit fortwährend die Prämisse, dass insbesondere das \ac{CCD} aufgrund seiner sequenziellen Augmentierbarkeit (Screening $\to$ lineares Modell $\to$ quadratische Modellterme, vgl. Abbildung~\ref{fig:abb2.08_strategy}) im Kontext kostenintensiver \ac{EoL}-Tests in der Zuverlässigkeitstechnik einen entscheidenden operativen Vorzug bieten kann und daher für die vorliegende Untersuchung und den praktischen Kontext als relevant erachtet wird.\\

Dieses Kapitel untersucht daher vorab systematisch die Auswirkungen geometrischer Design-Abweichungen auf die statistische Güte (Abschnitt~\ref{sec:abweichungen}).
Zunächst unabhängig von einer möglichen Beschleunigung durch \ac{ALT} wird vorab analysiert, inwieweit typische Manipulationen der Design-Geometrie (z.B. variierende Koordinaten oder Replikationen vereinzelter Versuchspunkte) oder mangelnde Robustheit der Versuchspunkt-Einstellungen (z.B. Varianzen in der Steuerung unabhängiger Versuchsparameter) die Versuchsplanperformance beeinflussen.
Um letztendlich \textit{effiziente} Konfigurationen von Versuchsplänen zu identifizieren, muss als übergeordnete Metrik die resultierende \textit{Effektivität} des Versuchsplans in Form der \textbf{statistischen Trennschärfe \sym{power}} gemessen werden (vgl. Abschnitt~\ref{sec:bewertung_stand}).
Dies ermöglicht schlichtweg eine Identifikation von relevanten Auswirkungen von Orthogonalitäts-Abweichungen auf die Trennschärfe (\sym{power}) der Versuchspläne, was letztendlich Potenziale in der Versuchsplanung aufzeigen kann.
Darauf aufbauend wird im Anschluss ein Kostenmodell eingeführt, das die monetären Konsequenzen derartiger Modifikationen quantifiziert (Abschnitt~\ref{sec:kostenmodell}).
Die Bewertung der Versuchspläne erfolgt dabei streng nach der Kerndefinition von Effizienz als Maß für die \textit{Leistungsfähigkeit}: Welche Information wird perspektivisch generiert und welcher monetäre Aufwand steht dem gegenüber?
Während die Informationsgüte konventionell über die Varianz der Parameterschätzung oder Prognoseunsicherheit - also Optimalitätskriterien - und die Kosten über das Modell quantifiziert werden, erweitert der hier verfolgte makroskopische Ansatz die Betrachtung entscheidend um die \textbf{statistische Trennschärfe \ac{power}}.
Diese fungiert als sensibler Indikator für die Erfolgsgarantie der perspektivischen Testagenda: Sie beziffert die Wahrscheinlichkeit, mit der real existierende Effekte tatsächlich signifikant erkannt werden.
Was in der allgemeinen \ac{DoE}-Methodik oft als nachgeordnete Größe behandelt wird, avanciert bei kostenintensiven \ac{EoL}-Tests zum kritischen Faktor.
Jede Manipulation des Designs - sei es zur Anpassung an \ac{ALT}-Niveaus oder aufgrund von Versuchsraum-Restriktionen - muss daher zwingend gegen den Verlust an Detektionswahrscheinlichkeit abgewogen werden, was in der ökonomischen Leitfrage mündet: \textit{Wie viel Trennschärfe ist finanzierbar?}
Um diese komplexen Abhängigkeiten generisch und losgelöst von spezifischen Produktdaten abzuleiten, sind numerische Simulationen erforderlich.
Mithilfe von \acp{MCS} und zunächst fiktiven physikalischen Modellen wird die Entwicklung dieser Verhältnismäßigkeiten in dieser Studie systematisch untersucht und aufgezeigt.

Zur Bewertung der Prognosegüte wird eine Erweiterung bestehender Visualisierungsmethoden vorgestellt (Abschnitt~\ref{sec:visualisierung}), bevor die Gesamtmethodik abschließend in der numerischen Simulationsstudie bewertet wird (Abschnitt~\ref{sec:simulation}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Analyse generischer Design-Abweichungen} \label{sec:abweichungen}
Moderne Versuchsplanung für die Zuverlässigkeitstechnik erfordert oft ein Abweichen vom idealen Lehrbuch-Design.
Sei es durch physikalische Restriktionen des Prüfstands oder der physikalischen Performance des Systems im \ac{ALT}, die eine orthogonale Positionierung der Versuchspunkte generell oder spezifisch die symmetrische Platzierung der Sternpunkte verhindern, oder durch die bewusste Manipulation des Versuchsraums, um die Extrapolationsgüte in Richtung einer spezifischen Anwendungsbelastung zu steigern.
Insbesondere im Kontext der Lebensdauerprognose sind solche Eingriffe aus der Praxis begründet gängig.
Beispielsweise kann die Verschiebung der Majorität der Versuchsumfänge in Richtung höherer Lastniveaus die Prüfzeit verkürzen, was die Gesamtkosten des Versuchsumfangs weiter reduziert (vgl. Abschnitt~\ref{sec:kostenmodell}).
Konträr ermöglicht die Verortung der Versuchspunkte näher zum Operationsbereich als Brücke zwischen Test- und Feldraum eine verbesserte Modellanpassung und reduziert die Extrapolationsunsicherheit, steigert aber in der Regel die Prüfzeit.

Allerdings bergen solche Modifikationen das Risiko, die statistische Integrität des Designs zu beeinträchtigen.
Im Idealfall sind die Design-Matrix-Spalten eines \ac{CCD} orthogonal zueinander, was eine unabhängige Schätzung der Modellparameter ermöglicht (vgl. Abschnitt~\ref{subsubsec:rsm}).
Jede dieser geometrischen Verzerrungen führt zwangsläufig zu einem Verlust der Orthogonalität (vgl. Gleichung~\ref{eq:skalar}).
Ein Umstand der mit möglicher Unwissenheit über perspektivisch optimale Versuchsraumbereiche wie in Abschnitt~ref{sec:screening} geschildert direkt einhergeht.

Auswirkungen peripherer Parametersetups erscheinen in sequentiellen Versuchsplänen besonders kritisch - aber chronologisch erst zu einem späteren Zeitpunkt erkennbar.
Erst nach vollständiger Durchführung der initialen Screening-Phase sowie der faktoriellen Versuchsdurchführung wird das Design um die Stern- und Zentralpunkte erweitert.
Im Umkehrschluss bedeutet dies, dass erst hier die volle Auswirkung von Design-Abweichungen auf die Modellgüte und Prognoseunsicherheit in der Praxis sichtbar werden kann, insbesondere dann, wenn extreme Parametereinstellungen zur Anwendung kommen.
Daher ist es essenziell, die Robustheit des \ac{CCD} gegenüber typischen Design-Abweichungen systematisch zu untersuchen, was im Folgenden dokumentiert wird.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Methodik der stochastischen Simulation und Modellbildung} \label{subsec:simulationsmethodik}

Um die Auswirkungen von Design-Abweichungen auf die statistische Güte quantifizieren zu können, bedarf es einer kontrollierten Untersuchungsumgebung, in der - im Gegensatz zu physischen Experimenten - die „wahre“ Natur des Systems bekannt ist und folglich vorgegeben wird.
Nur durch den Vergleich der Analyseergebnisse mit einer vorab definierten Wahrheit (\textit{Ground Truth}) lassen sich Metriken wie die Schätzpräzision und besonders die $\sym{power}$ valide bestimmen.
Zu diesem Zweck wird eine Simulationsumgebung geschaffen, die auf einem \textbf{scheinbar-physikalischen Modell} basiert.

\textbf{Das scheinbar-physikalische Modell} \\
Das zugrundeliegende Systemverhalten wird durch ein polynomiales Regressionsmodell zweiter Ordnung approximiert.
Dies entspricht der Struktur, die auch als Ergebnis der \ac{RSM}-Untersuchung erwartet wird (vgl. Gleichung~\ref{eq:quadric_std_model}).
Um die Anforderungen an eine multivariate Untersuchung ($\sym{k} \ge 2$) zu erfüllen und gleichzeitig die Komplexität handhabbar zu halten, wird im Basisszenario von $\sym{k}=2$ Faktoren $\sym{x}_1$ und $\sym{x}_2$ ausgegangen.
Es wird angenommen, dass sich die hierbei gewonnenen Erkenntnisse prinzipiell auf höherdimensionale Räume übertragen lassen.
Das Modell berücksichtigt neben den Haupteffekten explizit die für die Lebensdaueranalyse kritischen Wechselwirkungen ersten Grades sowie quadratische Terme zur Abbildung von Nichtlinearitäten analog zu Gleichung~\ref{eq:quadric_std_model}:
\begin{equation} \label{eq:simulation_model}
    \sym{y}_{\sym{idx_sim}} = \sym{beta}_{0} + \sym{beta}_{1}\sym{x}_{1} + \sym{beta}_{2}\sym{x}_{2} + \sym{beta}_{12}\sym{x}_{1}\sym{x}_{2} + \sym{beta}_{11}\sym{x}_{1}^2 + \sym{beta}_{22}\sym{x}_{2}^2 + \sym{epsilon}.
\end{equation}
Um ein realistisches, stochastisches Verhalten abzubilden, sind die Modellparameter nicht deterministisch fixiert.
Den Regressionskoeffizienten $\symsub{beta}{idx_j}$ werden zwar nominale Startwerte zugewiesen, diese werden jedoch in jedem Simulationslauf mit einer definierten Streuung überlagert.
Dies simuliert die natürliche Variabilität der Effektstärken in realen Anwendungen als \textit{epistemische Unsicherheit}.
Zusätzlich wird die resultierende Systemantwort $\sym{y}_{\sym{idx_sim}}$ mit einer Reststreuung $\sym{epsilon}$ beaufschlagt.
Dabei wird die inhärente \textit{aleatorische Unsicherheit} des Systems modelliert, die nicht durch die erklärenden Variablen abgedeckt wird (z.B. Messfehler, unbekannte Einflussgrößen).
Dieses Vorgehen stellt sicher, dass für jede Kombination aus Faktor-Einstellung und Koeffizienten-Set eine stochastisch variable Systemantwort erzeugt wird.

\textbf{Simulationsalgorithmus und Monte-Carlo-Ansatz}\\
Dieses Modell wird anschließend mit den zu untersuchenden Versuchsplänen gekoppelt.
Für jeden Stützpunkt des Versuchsplans (sei es ein ideales Standard-\ac{CCD} oder ein geometrisch manipuliertes Design mit verschobenen oder entfallenen Punkten) werden die korrespondierenden Systemantworten simuliert.
Verfügt der Versuchsplan über den vollständigen Vektor an Systemantworten, erfolgt die Rückrechnung (Schätzung) des Regressionsmodells mittels \ac{MLE} oder \ac{OLS}.

Da ein einzelner Durchlauf aufgrund der Stochastik lediglich eine Momentaufnahme darstellt, wird das Verfahren in eine **Monte-Carlo-Simulation** mit $\symsub{n}{idx_MC} = 10.000$ Iterationen eingebettet.
Dieser Ansatz erlaubt die generische Bewertung der Design-Qualität anhand zweier zentraler Kriterien:

\begin{enumerate}
    \item \textbf{Präzision der Parameterschätzung:} Durch den Vergleich der im Versuch geschätzten Parameter $\hat{\sym{beta}}$ mit den im Simulationsschritt vorgegebenen „wahren“ Koeffizienten $\sym{beta}_{\text{true}}$ lässt sich die durchschnittliche Abweichung (Bias) und Varianz der Schätzung ermitteln. Dies erfolgt normiert über die absichtlich induzierten Varianzen, um die reine geometrische Güte des Designs zu isolieren.

    \item \textbf{Bestimmung der Trennschärfe (Power):} Von übergeordneter Bedeutung ist die Auswertung der Signifikanztests. Für jeden der $\symsub{n}{idx_MC}$ Läufe und jeden Koeffizienten wird der zugehörige $\sym{p-Wert}$ berechnet.
          Die empirische \ac{power} ergibt sich aus dem Verhältnis der Fälle, in denen der Effekt korrekt als signifikant erkannt wurde, zur Gesamtzahl der Simulationen:
          \begin{equation} \label{eq:sim_power}
              \sym{power} = \frac{1}{\symsub{n}{idx_MC}} \sum_{i=1}^{\symsub{n}{idx_MC}} \mathbb{I}(\sym{p-Wert}_i < \sym{alpha}).
          \end{equation}
\end{enumerate}

Die Implementierung dieses fiktiven Systems ist eine notwendige Voraussetzung, um den Einfluss von Design-Modifikationen auf die \ac{power} überhaupt messbar zu machen.
Da die Trennschärfe jedoch nicht nur von der Geometrie des Versuchsplans, sondern maßgeblich vom Verhältnis aus Effektstärke zu Rauschen abhängt, muss eine umfassende Sensitivitätsanalyse (vgl. nachfolgenden Abschnitt) nicht nur geometrische Merkmale variieren, sondern auch die Parameter des scheinbar-physikalischen Modells selbst (z.\,B. Signal-Rausch-Verhältnis) als Einflussfaktoren berücksichtigen.

\subsection{Sensitivitätsanalyse geometrischer und stochastischer Einflussgrößen} \label{subsec:sensitivitaetsanalyse}

Um die Robustheit des \ac{CCD} gegenüber den eingangs erwähnten Abweichungen quantitativ zu bewerten, wurde eine umfassende Simulationsstudie durchgeführt.
Der methodische Ansatz folgt einem \textit{Design of Experiments on Experiments}-Konzept: Die Eigenschaften des zu untersuchenden Versuchsplans sowie der Systemantwort werden als Faktoren eines übergeordneten Meta-Designs variiert.
Im Gegensatz zu reinen Screening-Ansätzen kam hierfür ein **Zentral-Zusammengesetzter Versuchsplan (CCD) mit Blockbildung** zum Einsatz (vgl. Kapitel 4.1 der zugrundeliegenden Studie).
Die Wahl dieses Designs ermöglichte nicht nur die Identifikation linearer Haupteffekte, sondern auch die Analyse nicht-linearer (quadratischer) Einflüsse der Störgrößen auf die Performance-Metriken. Durch die Aufteilung in orthogonale Blöcke konnte der umfangreiche Parameterraum von acht Einflussfaktoren (a bis h) effizient und statistisch abgesichert untersucht werden.

Die in der Studie definierten acht Faktoren bilden sowohl deterministische geometrische Manipulationen am Versuchsplan als auch stochastische Störgrößen und Modellparameter ab:

\begin{itemize}
    \item \textbf{Faktor a (Sternpunkt-Abstand $\alpha$):} Variation des Abstands der Sternpunkte zum Zentrum, um den Einfluss der Raumausdehnung (z.\,B. flächenzentriert vs. rotierbar) zu prüfen.
    \item \textbf{Faktor b (Sternpunkt-Shift):} Asymmetrische Verschiebung eines Sternpunkts in Richtung eines anderen Faktors, was eine geometrische Verzerrung simuliert.
    \item \textbf{Faktor c (Zentralpunkte):} Variation der Anzahl der Zentralpunkte (Center Points Omitted).
    \item \textbf{Faktor d (Sternpunkte):} Variation durch das Weglassen von Sternpunkten (Star Points Omitted), z.\,B. durch Ausfall eines Probekörpers.
    \item \textbf{Faktor e (System-Rauschen):} Das Verhältnis zwischen dem Modellkoeffizienten und der Standardabweichung des Systems (Systemfehler).
    \item \textbf{Faktor f (Effekt-Verhältnis):} Das Verhältnis zweier Haupteffekte zueinander (Dominanz eines Faktors).
    \item \textbf{Faktor g (Mess-Rauschen):} Das Verhältnis zwischen dem Modellkoeffizienten und dem überlagerten Messfehler.
    \item \textbf{Faktor h (Signifikanzniveau):} Das für den Hypothesentest gewählte $\alpha$-Niveau.
\end{itemize}

Die Auswertung der Simulationsergebnisse mittels Varianzanalyse (ANOVA) und Wirkungsflächenanalyse offenbart eine signifikante Dichotomie in der Sensitivität der Zielgrößen:

Hinsichtlich der **statistischen Power** dominieren eindeutig die stochastischen und methodischen Faktoren.
Insbesondere Faktor **g** (Messfehler) und Faktor **h** (Signifikanzniveau) sowie Faktor **e** (Systemfehler) weisen die stärksten Effekte auf. Dies bestätigt, dass die Detektionswahrscheinlichkeit eines Effekts primär durch das Signal-Rausch-Verhältnis limitiert wird.
Die geometrischen Design-Faktoren (**a, b, c**) zeigten im untersuchten Bereich – selbst unter Berücksichtigung quadratischer Terme – einen vergleichsweise geringen Einfluss auf die Power.
Selbst die Reduktion der Sternpunkte (Faktor **d**) führte nicht zwangsläufig zu einem kritischen Einbruch der Trennschärfe, solange das Rauschen kontrolliert blieb.

Bezüglich der **Schätzgüte** (Differenz zwischen wahrem und geschätztem Koeffizienten) gewinnen die geometrischen Faktoren jedoch an Bedeutung.
Hier konnte durch das CCD-Meta-Design nachgewiesen werden, dass insbesondere die Anzahl der Zentralpunkte (Faktor **c**) einen nicht-linearen Einfluss auf die Schätzung quadratischer Modellterme hat. Auch Interaktionen zwischen geometrischen Faktoren (z.\,B. **a** und **b**) traten deutlicher hervor, was auf die Sensitivität der Modellierung gegenüber der Orthogonalität hinweist.

Zusammenfassend lässt die Studie den Schluss zu, dass das \ac{CCD} eine hohe Robustheit bezüglich der reinen Effektdetektion (Power) aufweist, selbst wenn die Geometrie „unsauber“ ist.
Die Präzision der Modellierung (Schätzgüte) reagiert jedoch sensibler auf geometrische Eingriffe.
Für die Praxis der Lebensdauererprobung bedeutet dies: Anpassungen an \ac{ALT}-Restriktionen sind vertretbar, wenn das primäre Ziel der Nachweis eines Effekts ist; für präzise Prognosemodelle ist die geometrische Integrität jedoch strikter zu wahren.





\subsection{Praktische Orthogonalitäts-Abweichungen im CCD} \label{subsec:orthogonalitaetsabweichungen}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Ökonomische Bewertung: Das Kostenmodell} \label{sec:kostenmodell}
Eine rein statistische Bewertung greift in der industriellen Praxis zu kurz.
Eine Design-Modifikation, die die Prädiktionsvarianz um 5\% senkt, aber die Versuchskosten verdoppelt, ist ineffizient.
Daher wird ein Kostenmodell eingeführt, das die monetären Aufwände eines Lebensdauerversuchs in Abhängigkeit der Design-Parameter abbildet.
Die Gesamtkosten $\symsub{C}{idx_total}$ setzen sich additiv aus fixen und variablen Anteilen zusammen:
\begin{equation} \label{eq:kostenmodell}
    \symsub{C}{idx_total} = \symsub{C}{idx_fix} + \left( \sym{n} \cdot \symsub{C}{idx_spec} \right) + \left( \sum_{\sym{idx_i}=1}^{\sym{n}} \symsub{t}{idx_test}_{\sym{idx_i}}(\symsub{x}{idx_i}) \cdot \symsub{C}{idx_time} \right) + \symsub{C}{idx_fail}.
\end{equation}
Hierbei beschreibt $\symsub{C}{idx_fix}$ die Rüstkosten, $\symsub{C}{idx_spec}$ die Herstellkosten pro Prüfling und $\symsub{C}{idx_time}$ die laufenden Betriebskosten des Prüfstands pro Zeiteinheit.
Der Term $\symsub{t}{idx_test}_{\sym{idx_i}}(\symsub{x}{idx_i})$ ist die entscheidende, vom Versuchsplan abhängige Größe: Durch \ac{ALT} (hohe Lastniveaus $\sym{x}$) sinkt die Prüfzeit, was $\symsub{C}{idx_total}$ reduziert.
Gleichzeitig steigt jedoch durch aggressive Lasten potenziell der Energiebedarf oder das Risiko nicht-repräsentativer Ausfallmechanismen ($\symsub{C}{idx_fail}$).
Dieses Modell ermöglicht es, Design-Alternativen nicht nur nach ihrer statistischen Effizienz (D-, G-Effizienz), sondern nach ihrer \textit{ökonomischen Effizienz} (Information pro Euro) zu bewerten.
Dieses Modell ermöglicht es, Design-Alternativen nicht nur nach ihrer statistischen Effizienz (D-, G-Effizienz), sondern nach ihrer \textit{ökonomischen Effizienz} (Information pro Euro) zu bewerten.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Evaluierung vielversprechender Design-Alternativen} \label{sec:design_alternativen}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bewertung der Versuchsplananpassung mittels Orthogonalitäts-Check} \label{sec:orthogonalitaets_check}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Erweiterte Methoden zur Prädiktions-Visualisierung} \label{sec:visualisierung}
Zur Beurteilung der Vorhersagegüte im gesamten Versuchsraum haben sich der \textbf{\ac{VDG}} und der \textbf{\ac{FDS}-Plot} etabliert.
Diese Metriken bewerten die Verteilung der skalierten Prädiktionsvarianz (\ac{SPV}) jedoch oft global oder über sphärische Distanzen gemittelt.
Für die Lebensdauerprognose, bei der oft eine Extrapolation in einen spezifischen, eng begrenzten Anwendungsbereich ("Corner Case") von Interesse ist, sind diese globalen Maße oft unzureichend.

Daher wird in dieser Arbeit eine neue, erweiterte Auswertungsmethode vorgestellt: Das \textbf{Extrapolations-spezifische SPV-Mapping}.
Im Gegensatz zum klassischen VDG, der die Varianz über Radien mittelt, visualisiert diese Methode die Isolinien der Prädiktionsvarianz explizit in Richtung der relevanten Belastungsvektoren.
Dies ermöglicht die gezielte Bewertung der Design-Güte exakt in jenen Bereichen des Parameterraums, in denen die spätere Feldprognose erfolgen soll, und deckt Schwachstellen auf, die in globalen FDS-Plots verborgen blieben.

\section{Simulative Validierung und Methodennachweis} \label{sec:simulation}
Aufgrund der unendlichen Kombinationsmöglichkeiten von Einflussfaktoren, Lastniveaus und physikalischen Modellen ist eine generische Sensitivitätsanalyse für alle denkbaren Anwendungsfälle nicht zielführend.
Stattdessen wird die Anwendbarkeit und Leistungsfähigkeit der vorgeschlagenen Methodik am Beispiel eines generischen Referenzsystems mittels Monte-Carlo-Simulation (MC) nachgewiesen.

\subsection{Simulationssetup}
Als Referenzsystem dient ein Weibull-verteiltes System ($\sym{b}=2, \sym{T}=1000\,\text{h}$), dessen Lebensdauerverhalten durch ein log-lineares Modell mit zwei Hauptfaktoren und einer Wechselwirkung beschrieben wird.
Im Rahmen der MC-Simulation werden $\symsub{n}{idx_MC} = 10.000$ virtuelle Versuchsreihen erzeugt, wobei für jeden Lauf:
1.  Lebensdauerdaten basierend auf dem definierten Modell und den Versuchsplan-Stützstellen (modifiziertes CCD vs. Benchmark-CCD) generiert werden.
2.  Eine stochastische Streuung sowie Zensierung (Typ I/II) aufgeprägt wird.
3.  Die Modellparameter mittels \ac{MLE} zurückgeschätzt werden.

\subsection{Ergebnisse und Effizienzbewertung}
Die Auswertung erfolgt multidimensional anhand der in den vorangegangenen Abschnitten definierten Metriken:
\begin{itemize}
    \item \textbf{Power:} Wie hoch ist die Wahrscheinlichkeit, die definierten Effekte trotz Design-Manipulation korrekt zu detektieren?
    \item \textbf{Parameterschätzgüte:} Wie verhalten sich Bias und Varianz der Schätzer ($\hat{\sym{b}}, \hat{\sym{T}}$) bei Verlust der Orthogonalität?
    \item \textbf{Ökonomische Bilanz:} Welches Design liefert die geforderte Präzision bei minimalen Gesamtkosten gemäß Gleichung~\ref{eq:kostenmodell}?
\end{itemize}
Durch den Vergleich der gesampleten Versuchszeiten (Time-to-Failure) kann valide auf die Effizienz im \ac{ALT}-Kontext geschlossen werden.
Es wird gezeigt, dass ein gezielt manipuliertes CCD, bei dem Sternpunkte in Richtung der Hauptbelastung verschoben werden, die Prognoseunsicherheit im Anwendungsbereich signifikant senken kann, ohne die maximale Versuchsanzahl oder das Budget des konventionellen Benchmarks zu überschreiten.
Damit wird der Nachweis erbracht, dass die entwickelte Methodik zur Bewertung und Anpassung von Versuchsplänen (Kostenmodell + SPV-Visualisierung + Orthogonalitäts-Check) ein robustes Werkzeug zur Steigerung der Testeffizienz darstellt.