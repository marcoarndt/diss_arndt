%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Kapitel 3 - Ansatz %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Effiziente Testplanung für die multivariate Lebensdauererprobung} \label{chap:ansatz}

\section{Bewertung des Standes der Forschung und Technik} \label{sec:bewertung_stand}
Der in Kapitel~\ref{chap:stand} dargelegte Stand zur Versuchsplanungsmethodik verdeutlicht, dass sowohl die Zuverlässigkeitstechnik als auch die statistische Versuchsplanung (\ac{DoE}) für sich genommen etablierte Disziplinen mit einem umfangreichen Methodenrepertoire darstellen.
Die Schnittmenge beider Felder, die effiziente Planung multivariater Lebensdauerversuche unter Berücksichtigung nicht-normalverteilter Daten und Zensierung, weist jedoch spezifische Lücken auf, die den Bedarf an weiterführender Forschung begründen.

\subsection*{Eignung klassischer Response Surface Designs}
Klassische Versuchspläne der \ac{RSM}, insbesondere das \textbf{\ac{CCD}}, haben sich als robuster Standard für die Modellierung nicht-linearer Zusammenhänge bewährt.
Ihre Stärken liegen in der sequenziellen Augmentierbarkeit, der Rotierbarkeit und der Fähigkeit zur unabhängigen Schätzung des reinen Fehlers (vgl. Abschnitt~\ref{subsubsec:rsm}).
Für die spezifischen Anforderungen der Lebensdauererprobung, die häufig eine Extrapolation der Ergebnisse aus einem hochbelasteten Testraum (\ac{ALT}) in einen niedriger belasteten Anwendungsraum erfordert, ist die starre Symmetrie des klassischen \ac{CCD} jedoch nicht zwangsläufig optimal.
Es existieren zwar bereits vereinzelte Ansätze zur Modifikation von \acp{CCD}, wie die Arbeiten von \textcite{Ahn.2015, Donev.2004, G.E.P.Box.1951} und \textcite{Ardakani.2011} zeigen.
Diese fokussieren sich jedoch zumeist auf generische Optimalitätskriterien oder spezifische geometrische Restriktionen und adressieren nicht explizit die Herausforderungen der probabilistischen Lebensdauerprognose unter Extrapolation im Kontext der \textbf{Trennschärfe} bzw. \textbf{\sym{power}}.
Eine systematische Methodik zur gezielten Manipulation von Sternpunkten in Prognoserichtung zur Steigerung der Extrapolationsgüte bei gleichzeitiger Wahrung der Modelleigenschaften fehlt bislang weitgehend - obwohl aus praktischer, ingenieurwissenschaftlicher Sicht im Maschinen- und Fahrzeugbau durchaus relevant.

\subsection{Limitationen optimaler Versuchspläne für GLMs}
Die Anwendung optimaler Versuchspläne (vgl. Abschnitt~\ref{subsec:optimal}) erscheint zunächst als logische Konsequenz, um maßgeschneiderte Designs für Lebensdauererprobungen zu entwerfen.
Die zugrundeliegende Modellierung mittels \textbf{Weibull-\acp{GLM}} stößt hierbei jedoch auf ein fundamentales Problem, das von \textcite{Khuri.2006} und \textcite{Stufken.2012} ausführlich diskutiert wird:
Im Gegensatz zu linearen Modellen mit binären Ausgängen in $\sym{y}$ hängt die Informationsmatrix bei \acp{GLM} (und damit auch die Optimalität eines Designs) nicht nur von den Einstellungen der Faktoren $\sym{X}$, sondern auch von den unbekannten Modellparametern $\sym{theta}$ (hier $\sym{beta}$-Koeffizienten sowie Weibull-Formparameter $\sym{b}$) ab.
So konnten im Gegensatz zu linearen Modellen zwar  keine geschlossenen Formeln für optimale Designs abgeleitet werden, jedoch existieren diverse Algorithmen zur numerischen Bestimmung optimaler Versuchspläne für \acp{GLM} \cite{Khuri.2006}.
Diese Verfahren setzen jedoch stets voraus, dass die wahren Parameterwerte $\sym{theta}$ bereits bekannt sind oder zumindest verlässlich (\textit{best guess}) geschätzt werden können.
\textcite{Stufken.2012} führen hierzu aus, dass optimale Designs für \acp{GLM} \textit{lokal} optimal sind, also nur für a priori gewählte Parameterwerte gelten.
Da diese Parameter (z.B. der Weibull-Formparameter $\sym{b}$ oder die charakteristische Lebensdauer $\sym{T}$) im Vorfeld einer Lebensdaueruntersuchung jedoch unbekannt sind und höchstens über Bayes'sche Methoden mit hoher Unsicherheit geschätzt werden können, existieren keine universell optimalen \ac{GLM}-Designs für die Weibull-Lebensdauermodellierung.
Ein Design, das für einen angenommenen Parametersatz optimal ist, kann sich bei Abweichung der realen Werte als ineffizient erweisen ("The designs may be poor if the choice of values is far from the true parameter values", \textcite{Stufken.2012}).

\subsection*{Schlussfolgerung für die effiziente multivariate Testplanung}
Aus dieser Diskrepanz leitet sich die Notwendigkeit einer pragmatischen und zugleich statistisch fundierten Vorgehensweise ab.
Anstatt sich auf die Suche nach einem theoretisch \textit{optimalen} \ac{GLM}-Design zu versteifen, das aufgrund der Parameterabhängigkeit in der Praxis kaum robust umsetzbar ist, erscheint die Adaption bewährter Standard-Designs vielversprechender.
Dabei müssen die etablierten Optimalitätskriterien jedoch nicht als alleiniges Entwurfsziel, sondern als Benchmark-Metriken herangezogen werden:
\begin{itemize}
    \item \textbf{Modellierungsgüte (A-, D-Kriterien):} Diese Metriken sichern ab, dass die Parameterschätzung (Bestimmung von $\sym{beta}$, $\sym{b}$) auch im modifizierten Design statistisch solide und präzise bleibt.
    \item \textbf{Prognosefähigkeit (G-, I-, V-Kriterien):} Diese Metriken gewinnen im Kontext der Lebensdauererprobung an primärer Bedeutung, da das Ziel meist nicht nur die Modellierung an sich, sondern die präzise Vorhersage der Zuverlässigkeit $\sym{R}(\sym{t})$ unter Einsatzbedingungen (Extrapolation) ist.
\end{itemize}
Eine effiziente Testplanung für die multivariate Lebensdauererprobung muss folglich einen Kompromiss finden: Sie muss flexibel genug sein, um Extrapolationen durch \ac{ALT} gezielt zu unterstützen (z.B. durch Anpassung des \ac{CCD}), und gleichzeitig robust genug, um die Unsicherheiten der nicht-linearen \ac{GLM}-Parameterschätzung abzufangen.
Die Entwicklung einer solchen Methodik, welche die Vorteile klassischer \acp{RSD} mit den Anforderungen der Zuverlässigkeitsprognose verknüpft und quantitativ bewertbar macht, steht im Fokus der nachfolgenden Kapitel.

\begin{itemize}
    \item \cite[Kap. 9.1.4]{Myers.2016}
    \item \cite[Kap. 9.2.1]{Myers.2016}
    \item \colorbox{yellow}{\cite[Chapter. 27]{Cui.2021}}
    \item Monte-Carlo-Ansatz: \textcite{Escobar.1995}
    \item \textcite[Kap.13]{Box.2007}
    \item Evaluierung eines effizienten Versuchsplans vor Versuchsdurchführung: \textcite{Johnson.2011}
    \item Manipulationen im CCD: \textcite{Ahn.2015,Donev.2004,G.E.P.Box.1951,Ardakani.2011}
    \item Optimale versuchspäne  \textcite{Jones.2012}
    \item Khuri - 2006 - Design Issues for Generalized Linear Models A Review
    \item Stufken in Hinkelmann - 2012 - Optimal Designs for Generalized Linear Models with Applications
    \item Yang - 2011 - OPTIMAL DESIGNS FOR GENERALIZED LINEAR MODELS WITH MULTIPLE DESIGN VARIABLES
    \item \cite[Seite 314]{Rigdon.2022}
    \item Monroe, E.M., Pan, R., Anderson-Cook, C. et al. (2011). A generalized linear model approach to designing accelerated life test experiments. Quality and Reliability Engineering International 27: 595-607.
\end{itemize}

\cite{Khuri.2006,Stufken.2012}

\subsubsection{Besonderheiten der Effizienz in der Lebensdauerprüfung}
Der Begriff der Effizienz erfährt im Kontext der Planung multivariater Lebensdauertests (\ac{ALT} oder Reliability Demonstration Tests) eine signifikante Erweiterung gegenüber der klassischen linearen Versuchsplanung.
Während Standard-Designs primär die Varianz der Parameterschätzer minimieren, unterliegen Lebensdauertests der zusätzlichen Restriktion, dass die Information (der Ausfall eines Bauteils) stochastisch über die Zeit generiert wird und oft durch \textbf{Zensierung} limitiert ist.

Eine zentrale Herausforderung besteht in der \textbf{Modellabhängigkeit} (engl. Model Dependence) der Informationsmatrix.
Bei nicht-linearen Modellen, wie der in der Zuverlässigkeitstechnik omnipräsenten Weibull- oder Lognormal-Regression, ist die Fisher-Informationsmatrix $\sym{FIM}$ nicht mehr allein von der Versuchsplanmatrix $\sym{X}$ abhängig, sondern auch von den wahren, aber unbekannten Verteilungsparametern $\sym{theta}$ (z.\,B. Formparameter $\sym{b}$):
\begin{equation}
    \sym{M}(\sym{X}, \sym{theta}) = \sym{E} \left[ - \frac{\partial^2 \sym{L_like}(\sym{theta})}{\partial \sym{theta}^2} \right].
    \label{eq:fisher_info_depend}
\end{equation}
Daraus resultiert das Paradoxon, dass zur Konstruktion eines optimalen Plans bereits Kenntnisse über die zu ermittelnden Parameter vorliegen müssen.
Klassische Optimalitätskriterien (D-, A-Optimalität) wandeln sich daher zu \textbf{lokalen Optimalitäten}, die nur für einen spezifischen Parametervektor $\sym{theta}_0$ („Best Guess“) gültig sind.
Um Robustheit gegenüber Fehlannahmen dieser Startwerte zu gewährleisten, werden in der Entwicklung effizienter Lebensdauertests häufig \textbf{Bayes-Optimale Versuchspläne} eingesetzt, welche die Effizienz über eine A-Priori-Verteilung der Parameter maximieren \cite{Meeker.2022, Goos.2011}.

Zudem muss die \textbf{zeitliche Effizienz} berücksichtigt werden.
Ein Versuchsplan gilt im Kontext der Lebensdaueranalyse nur dann als effizient, wenn er unter Berücksichtigung der Zensierungsmechanismen (Typ-I oder Typ-II) die erwartete Anzahl an Ausfällen maximiert oder die \textbf{erwartete Testdauer} bei gegebener Präzision minimiert.
Die Varianz der Schätzung wird hierbei maßgeblich durch die Anzahl der ausgefallenen Einheiten getrieben, nicht allein durch die Stichprobengröße $\sym{n}$ \cite{Nelson.2005}.


\subsubsection{Abgrenzung zu weiteren Themen in der \ac{RSM}} \label{subsubsec:abgrenzung}

\begin{itemize}
    \item \textbf{\ac{GLM} Mixed Models}, \textbf{Random Effects} (Generalized Linear Mixed Models) \cite[Myers 2010 Kap.7.1.2]{Myers.2010}
    \item \textbf{Robuste Versuchspläne} (Robust Designs):
    \item \textbf{Adaptive Versuchspläne} (Adaptive Designs):
    \item \textbf{Bayesian Designs}, z.B. in \textcite{Englert.2012}
    \item \textbf{Sequential Designs}:
    \item \textbf{Optimalität für Vorhersagegüte}:
    \item \textbf{Optimalität für Klassifikationsaufgaben}:
    \item \textbf{Optimalität für multiple Zielgrößen}:
    \item \textbf{Robuste Optimale Versuchspläne} (Robust Optimal Designs):
    \item \textbf{Kombinierte Optimalitätskriterien} (Compound Optimal Designs):
    \item \textbf{Optimale Versuchspläne für Mischmodelle} (Optimal Designs for Mixed Models):
    \item \textbf{Optimale Versuchspläne für räumliche Modelle} (Optimal Designs for Spatial Models):
    \item \textbf{Optimale Versuchspläne für Zeitreihenmodelle} (Optimal Designs for Time Series Models):
    \item \textbf{Optimale Versuchspläne für nichtparametrische Modelle} (Optimal Designs for Nonparametric Models):
    \item \textbf{Optimale Versuchspläne für Hochdimensionale Modelle} (Optimal Designs for High-Dimensional Models):
    \item \textbf{Optimale Versuchspläne für dynamische Systeme} (Optimal Designs for Dynamic Systems):
    \item \textbf{Optimale Versuchspläne für Netzwerke} (Optimal Designs for Networks):
    \item \textbf{Optimale Versuchspläne für Big Data Anwendungen} (Optimal Designs for Big Data Applications):
    \item \textbf{Optimale Versuchspläne für maschinelles Lernen} (Optimal Designs for Machine Learning): \textcite{Colak.2024}
    \item \textbf{Optimale Versuchspläne für Künstliche Intelligenz} (Optimal Designs for Artificial Intelligence):
    \item \textbf{Optimale Versuchspläne für Quantencomputing} (Optimal Designs for Quantum Computing):
    \item \textbf{Optimale Versuchspläne für Blockchain-Technologien} (Optimal Designs for Blockchain Technologies):
    \item \textbf{Optimale Versuchspläne für Internet der Dinge (IoT)} (Optimal Designs for Internet of Things (IoT)):
    \item \textbf{Optimale Versuchspläne für Cyber-Physische Systeme} (Optimal Designs for Cyber-Physical Systems):
    \item \textbf{Optimale Versuchspläne für Nachhaltigkeit und Umweltwissenschaften} (Optimal Designs for Sustainability and Environmental Sciences):
\end{itemize}


\subsubsection{Bewertung und Abgrenzung: OMARS vs. CCD}
Im direkten Vergleich zum etablierten \ac{CCD} bieten \ac{OMARS}-Designs signifikante Vorteile für die Anwendung in der Lebensdauererprobung, die primär in ihrer Flexibilität und Effizienz begründet liegen.
Während ein \ac{CCD} durch seine geometrische Konstruktion eine starre Anzahl an Versuchen fordert (z.\,B. $N \ge 45$ für $\sym{k}=6$ Faktoren), ermöglichen \ac{OMARS}-Designs eine Entkopplung von Faktoren- und Versuchsanzahl.
Dies erlaubt die Realisierung von Designs mit geringerem Stichprobenumfang (z.\,B. $N=40$ für $\sym{k}=6$), ohne die Schätzbarkeit quadratischer Effekte zu verlieren.
Angesichts der hohen Kosten und langen Laufzeiten physikalischer Lebensdauertests stellt diese Reduktion einen erheblichen wirtschaftlichen Hebel dar.

Strategisch repräsentieren beide Ansätze unterschiedliche Philosophien: Der \ac{CCD} folgt oft einer sequentiellen Logik (Augmentierung nach Bedarf), was das Risiko minimiert, aber die Gesamtlaufzeit durch zwei Versuchsphasen verlängert.
\ac{OMARS}-Designs hingegen verfolgen einen \textit{One-Step}-Ansatz[cite: 376], der Screening und Optimierung integriert.
Dies ist insbesondere dann vorteilhaft, wenn Rüstzeiten hoch sind oder zeitliche Drifts (Chargeneffekte) zwischen zwei Versuchsphasen vermieden werden sollen.
Der Preis für diese Effizienz ist ein kontrolliertes Maß an \textit{Aliasing} zwischen Effekten zweiter Ordnung, welches jedoch durch die strikte Orthogonalität der Haupteffekte in der Praxis meist kompensiert wird .
Zusammenfassend qualifizieren sich \ac{OMARS}-Designs damit als präferierte Wahl für ressourcenbeschränkte Lebensdaueruntersuchungen, bei denen Nichtlinearitäten a priori nicht ausgeschlossen werden können.

% \subsection{Methodische Abgrenzung: Warum CCD statt OMARS?}
% Trotz der in der neueren Literatur diskutierten Effizienzvorteile von \ac{OMARS}-Designs (vgl. Abschnitt~\ref{sec:omars}) fiel die Wahl in dieser Arbeit bewusst auf das klassische \ac{CCD}.
% Diese Entscheidung begründet sich in drei spezifischen Anforderungen der vorliegenden Lebensdaueruntersuchung, die von \ac{OMARS}-Designs nicht im gleichen Maße adressiert werden:

% \begin{itemize}
%     \item \textbf{Sequentielles Risiko-Management:}
%           Im Gegensatz zum \textit{One-Step}-Ansatz der OMARS-Designs \cite{Goos.2025} ermöglicht das \ac{CCD} eine sequentielle Versuchsführung.
%           Angesichts der Unsicherheit über die physikalische Relevanz quadratischer Effekte erlaubt dies, zunächst mit einem faktoriellen Screening zu starten und Ressourcen für die Augmentierung (Sternpunkte) nur dann freizugeben, wenn Krümmungen signifikant nachgewiesen werden. Dies maximiert die Kontrolle über den Versuchsfortschritt.

%     \item \textbf{Rotierbarkeit für Extrapolation:}
%           Da die Lage des Zuverlässigkeitsoptimums a priori unbekannt ist und Prädiktionen oft in den Randbereich oder darüber hinaus (Extrapolation) erfolgen müssen, ist eine richtungsunabhängige Prädiktionsvarianz essenziell.
%           Durch die Wahl des Axialabstands $\alpha$ kann das \ac{CCD} exakt \textit{rotierbar} ausgelegt werden, eine Eigenschaft, die bei OMARS-Designs zugunsten der Orthogonalität oft in den Hintergrund tritt.

%     \item \textbf{Geringe Faktorenanzahl:}
%           Der Effizienzvorteil von OMARS-Designs kommt primär bei höheren Faktorenzahlen ($\sym{k} \ge 4$) zum Tragen, wo klassische Pläne unwirtschaftlich werden.
%           Für die hier betrachteten Systeme mit $\sym{k} < 3$ Faktoren bietet das \ac{CCD} ein optimales Verhältnis aus statistischer Power und Versuchsumfang, ohne die Komplexität der Auswertung unnötig zu erhöhen.
% \end{itemize}

\subsection{Forschungsfragen und Aufbau der Arbeit} \label{subsec:forschungsfragen}

Das übergeordnete Ziel dieser Arbeit, die Entwicklung effizienter multivariater Lebensdauerversuche, fußt auf der Prämisse, dass etablierte Standard-Designs nicht zwingend durch vollkommen neuartige Algorithmen ersetzt, sondern vielmehr intelligent adaptiert werden müssen.
Als methodischer Anker und Referenzpunkt dient hierbei das \textbf{\ac{CCD}}. Dieser Konsens begründet sich auf einer Synthese aus verfahrenstechnischen, physikalischen und statistischen Vorzügen, die das \ac{CCD} für die Zuverlässigkeitsmodellierung im Maschinen- und Fahrzeugbau prädestinieren.
Dies lässt sich aus praktischen Erfahrungen wie beispielsweise nach \textcite{Myers.2016,Kleppmann.2020} sowie einer Vielzahl wissenschaftlicher Publikationen ableiten  und umfasst insbesondere folgende Aspekte:
\begin{enumerate}
    \item \textbf{Sequenzielle Augmentierbarkeit:} Das Design unterstützt ideal den ökonomischen Zwang zur Ressourceneffizienz. Es ermöglicht eine schrittweise Erweiterung vom Screening über lineare Modelle bis hin zur quadratischen Modellierung. Dies erlaubt den Abbruch oder die Ausweitung von Versuchen basierend auf Zwischenergebnissen und minimiert das Risiko von Fehlinvestitionen bei zeitintensiven Lebensdauertests.
    \item \textbf{Universelle Prädiktionseigenschaften:} Da der exakte Betriebsbereich oder das Optimum der Zuverlässigkeit a priori oft unbekannt sind und Tests beschleunigt (Offset zwischen Test- und Feldraum) stattfinden, bietet die Rotierbarkeit des Designs günstige Voraussetzungen für eine richtungsunabhängige Prädiktionsgüte.
    \item \textbf{Wissenschaftliche Fundierung:} Das \ac{CCD} ist als breit diskutierter und gut erforschter Standard etabliert, was die Akzeptanz und Vergleichbarkeit der Ergebnisse im wissenschaftlichen und industriellen Umfeld sicherstellt.
    \item \textbf{Validierung physikalischer Modelle:} Durch die Variation auf fünf Faktorstufen ($-\alpha, -1, 0, +1, +\alpha$) ermöglicht das Design - im Gegensatz zu einfacheren Plänen - die Überprüfung der Gültigkeit physikalischer Beschleunigungsgesetze (z.B. Arrhenius) und die Detektion von Linearitätsabweichungen bei hohen Lasten.
    \item \textbf{Schätzung des reinen Fehlers:} Die Integration mehrfacher Zentralpunkte erlaubt eine robuste Schätzung der natürlichen Streuung (\textit{Pure Error}) unabhängig vom Anpassungsfehler des Modells (\textit{Lack of Fit}). Dies ist für die Berechnung verlässlicher Vertrauensbereiche der Zuverlässigkeit essenziell.
    \item \textbf{Orthogonale Blockbildung:} Das Design lässt sich exzellent in orthogonale Blöcke unterteilen. Dies ist für Langzeitversuche von entscheidender Bedeutung, um zeitliche Trends durch beispielsweise Chargenunterschiede statistisch zu bereinigen, ohne die Parameterschätzung zu verzerren.
    \item \textbf{Robustheit gegen Datenverlust:} Aufgrund seiner symmetrischen Struktur weist das \ac{CCD} eine hohe Toleranz gegenüber fehlenden Werten (\textit{Missing Data}) auf, was die Auswertbarkeit des Versuchs auch bei unvorhergesehenen Ausfällen oder technischer Zensierung auf dem Prüfstand weitgehend sichert.
\end{enumerate}
Ausgehend von diesem Status quo zielt die vorliegende Arbeit darauf ab, dieses bewährte Grundkonstrukt nicht zu verwerfen, sondern es gezielt für die spezifischen Anforderungen der Lebensdauerprognose zu modifizieren.Dies führt zur zentralen \textbf{Forschungsfrage} dieser Arbeit:
\\
\textbf{Wie können effiziente, multivariate Testdesigns (\acp{RSD}) entwickelt und geplant werden, um eine beschleunigte Lebensdauererprobung zum Zweck einer multivariaten Zuverlässigkeitsmodellierung umzusetzen?}\
\\
Zur Beantwortung dieser Hauptfragestellung werden folgende Teilfragestellungen abgeleitet:
\begin{enumerate}
    \item \textbf{Adaptionsbedarf und -strategie:} Wie und warum können bzw. sollen konventionelle Testdesigns (speziell das \ac{CCD}) angepasst werden? Ist eine Adaption bestehender Test-Designs, beispielsweise durch gezielte Manipulation der Sternpunkte in Prognoserichtung, sinnvoll und zielführend?
    \item \textbf{Bewertungsmethodik:} Wie können die Auswirkungen derartiger Manipulationen an \acp{CCD} auf die Prognosegüte quantitativ charakterisiert und vergleichbar bewertet werden?
\end{enumerate}

\subsubsection{Aufbau der Arbeit}
Der weitere Aufbau der Arbeit orientiert sich an der logischen Abfolge von der Parameteridentifikation bis zur Design-Optimierung.
In \textbf{Kapitel 4} wird zunächst das Themenfeld des Screenings adressiert.
Hier wird ein Vorschlag zu einem heuristischen Screening-Ansatz vorgestellt, der darauf abzielt, die Effizienz im Prozess der Parameterselektion gezielt für Lebensdauer-beeinflussende Faktoren zu steigern und somit die Basis für nachfolgende \acp{RSD} zu legen.
Grundsätzlich neu ist hierbei die Behandlung von mutmaßlichen Wechselwirkungen der Lebensdauer-beeinflussenden Faktoren im Screening-Prozess.
Darauf aufbauend widmet sich \textbf{Kapitel 5} der generischen Untersuchung und Bewertung von Versuchsplanabweichungen, ausgehend vom \ac{CCD} als Referenz.
In diesem Kontext werden ein Kostenmodell sowie ein neu entwickeltes Tool zur Bewertung der Prädiktionsgüte in Abhängigkeit der \ac{SPV} eingeführt.
Daraus abgeleitet werden konkrete Strategieempfehlungen für die Anpassung von \acp{CCD}, etwa zur Optimierung der Extrapolationsfähigkeit, vorgestellt und diskutiert.
Abschließend ist in \textbf{Kapitel 6} die Vorstellung einer Fallstudie (Case Study) vorgesehen, um die erarbeitete Methodik an einem praxisnahen Anwendungsbeispiel zu validieren und die theoretischen Erkenntnisse in den operativen Kontext zu transferieren.