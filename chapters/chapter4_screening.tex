%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Kapitel 4 - Parameter-Screening %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Parameter-Screening für multifaktorielle Lebensdauertests} \label{chap:screening}

Die in Kapitel~\ref{chap:ansatz} hergeleitete Notwendigkeit effizienter Testdesigns setzt voraus, dass die Anzahl der zu untersuchenden Faktoren $\sym{k}$ auf ein handhabbares Maß begrenzt ist.
Da die Komplexität und der Versuchsumfang exponentiell mit der Anzahl der Faktoren steigen (vgl. Gleichung~\ref{eq:ffvp_n}), ist eine präzise Vorselektion der Einflussgrößen entscheidend.
Klassische Ansätze der Versuchsplanung setzen hierfür oft auf experimentelle Screening-Pläne.
Im Kontext der Lebensdauererprobung führen diese jedoch zu einem Paradoxon: Um experimentell zu prüfen, ob ein Parameter die Lebensdauer beeinflusst, müssten gleichermaßen bei konventionellen Screeningdesigns (z.B. $2^{\sym{k}-\sym{p_f}}$ Designs, Plackett-Burman-Designs) sowie modernen \acp{RSD} (z.B. \ac{OMARS}-Designs) bereits zeitintensive \ac{EoL}-Tests durchgeführt werden, was den Effizienzvorteil des Screenings zunichtemacht.

Dieses Kapitel stellt daher einen effizienten methodischen Ansatz zum \textbf{heuristischen Screening} vor.
Ziel ist es, basierend auf Expertenwissen und systematischer Analyse eine qualitative Reduktion des Parameterraums vorzunehmen, \textit{bevor} physische Versuche gestartet werden \cite{Arndt.2023c}.
Dabei liegt der Fokus explizit auf der Unterscheidung zwischen bloßer Robustheit (zum Zeitpunkt $\sym{t}=0$) und echter Zuverlässigkeit (über die Zeit $\sym{t}>0$).
Aus der Perspektive der Zeitdomäne ist die differenzierte Klassifizierung der Einflussfaktoren für die Konzeption zuverlässigkeitstechnischer Untersuchungen von entscheidender Bedeutung.
Schließlich sind stochastische Degradationspfade entsprechend Abschnitt~\ref{subsec:begriffezuv} und die daraus resultierende Überlebenswahrscheinlichkeit $\sym{R}(\sym{t})$ nicht statisch zu betrachten, sondern zeitvarianten Interaktionsstrukturen und einer sich verschiebenden Effekthierarchie unterlegen.
Folglich kann das Parameterset, welches das Systemverhalten in fortgeschrittenen Phasen des Lebensdauerzyklus determiniert, signifikant von jenen Faktoren divergieren, die lediglich die initiale Performanceverteilung des Systems bei $\sym{t}=0$ dominieren.
Die Auswahl der relevanten Kovariaten ist somit inhärent dem Einfluss der Zeit ausgesetzt.
Um dieser Dynamik gerecht zu werden, synergiert der vorgestellte Ansatz teils bestens etablierte Kreativtechniken (z.B. Brainstorming, Fehlerbaum-Analysen - engl. \ac{FTA}, Ishikawa-Diagramme) mit strukturierten Bewertungswerkzeugen (z.B. \ac{DSM}, Grid-Analyse), um eine belastbare Identifikation und Priorisierung der kritischen Einflussgrößen zu gewährleisten.

\section{Identifikation potenzieller Einflussgrößen} \label{sec:screening_identifikation}
Die Basis eines jeden Screenings bildet die vollständige Erfassung aller potenziellen Einflussgrößen.
Um eine lückenlose Identifikation zu gewährleisten, ist eine strukturierte Systemanalyse unerlässlich, wie sie in der Zuverlässigkeitstechnik nach \textcite{Bertsche.2022} etabliert ist.
Ein zentrales Werkzeug hierfür ist das \textbf{Funktionsblockdiagramm}, engl. \textbf{\ac{FBD}} \cite{Lindemann.2008,Krallmann.2013,Gundlach.2004}.
Es abstrahiert das technische System auf seine Ein- und Ausgangsgrößen, klassifiziert nach den Flussgrößen \textit{Energie}, \textit{Stoff} und \textit{Signal} (vgl. Abbildung~\ref{fig:fbd_structure}) \cite{Pahl.2007}.
Innerhalb der Systemgrenzen werden Haupt- und Nebenfunktionen definiert, deren Nichterfüllung direkt zu potenziellen Ausfallmechanismen führt.
\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.9\textwidth}
    % \import{plots/}{J22-arndt-fu-subfu.pdf_tex}
    \caption{Funktionsstruktur mit Haupt-, Neben- und Teilfunktionen zur Identifikation von Einflussgrößen (nach \textcite{Wallace.2007})}
    \label{fig:fbd_structure}
\end{figure}
Zur initialen Sammlung der Parameter (Informationsbeschaffung) eignen sich, aufbauend auf dem \ac{FBD}, entsprechend \textcite{Montgomery.2020b,Bruckner.2019} klassische Methoden des Qualitätsmanagements (\ac{Q7} and \ac{M7}) sowie etliche Kreativtechniken:
\begin{itemize}
    \item \textbf{Literaturrecherche:} Analyse bestehender Ausfallmodi und physikalischer Wirkmechanismen (z.B. Arrhenius, Wöhler) aus vergleichbaren Anwendungen aber auch simulativen Untersuchungen (\ac{FEA}) \cite{Breiing.1997}.
    \item \textbf{Brainstorming} bzw. \textbf{ABC-Brainstorming} ermöglichen es interdisziplinären Expertenteams, intuitives Erfahrungswissen zu explizieren \cite{Daenzer.2002,Mayers.1997}.
    \item \textbf{Delphi-Methode:} Durch mehrstufige, anonymisierte Befragungen von Experten können subjektive Einschätzungen objektiviert und Konsens über potenzielle Einflussgrößen erzielt werden \cite{Daenzer.2002}.
    \item \textbf{Morphologische Analyse:} Durch die Zerlegung des Systems in Teilfunktionen und die Variation von Lösungsprinzipien werden systematisch konstruktive Einflussparameter aufgedeckt \cite{Albers.2005,Thompson.1999}.
\end{itemize}
Das Ergebnis dieses Schrittes ist eine unsortierte, aber möglichst vollständige Liste (Parameter-Pool) aller Größen, die potenziell auf das System einwirken.

\section{Kreativmethoden zum Auswahlprozesse im Parameter-Screening} \label{sec:kreativmethoden}
{Kreativmethoden zum Auswahlprozess im Parameter-Screening} \label{sec:screening_kreativ}
Nach der Identifikation muss der Parameter-Pool zunächst strukturiert und anschließend bewertet werden, um die vitalen Einflussgrößen (\textit{vital few}) von den trivialen (\textit{trivial many}) zu trennen, vergleiche \textcite{Arndt.2023c}.
Insbesondere basierend auf Arbeiten von \textcite{Gundlach.2004,Kremer.2018b,Mayers.1997} werden im Folgenden geeignete Methoden vorgestellt, die sich für das heuristische Screening im Kontext von zeitvarianten Parametersets in der Lebensdaueranalyse eignen und darüber hinaus auf Randbedingungen der Versuchsplanung Rücksicht nehmen.
\subsection{Strukturierungsmethoden} \label{subsec:Strukturierungsmethoden}
Nachdem durch die vorangegangenen Schritte der Informationsbeschaffung eine möglichst vollständige Sammlung aller potenziellen Systemparameter, Inputs und Outputs generiert wurde, bedarf es einer systematischen Strukturierung auf Basis eines vertieften Systemverständnisses.
Dieser Schritt darf sich nicht auf eine reine Clusterung in Parametergruppen beschränken.
Vielmehr gilt es, die \textit{gegenseitigen Beeinflussungen} der Größen zu identifizieren und zu offenbaren.
Insbesondere für die Lebensdaueranalyse stellt dies einen entscheidenden Mehrwert dar, der im Einklang mit den Prinzipien des \ac{L-DoE} steht \cite{Montgomery.2020,Kremer.2021}: Phänomene wie Alterungseffekte oder die zeitvariante Änderung von Materialeigenschaften sind physikalisch oft nicht trivial durch Einzelgrößen beschreibbar, sondern resultieren maßgeblich aus Interaktionen (vgl. Abbildung~\ref{fig:degradation_scheme}).
Um diese komplexen, teils zeitabhängigen Zusammenhänge für die weitere Selektion greifbar zu machen, eignen sich primär grafische Methoden, die über die reine Auflistung hinausgehen:

\begin{itemize}
    \item \textbf{Affinitätsdiagramm:} Als Werkzeug der \textit{M7} dient es der thematischen Clusterung der oft unstrukturierten Ergebnisse aus Brainstorming-Sessions \cite{Bruckner.2019}. Es ordnet Parameter übergeordneten Kategorien zu und deckt erste logische Gruppierungen auf, womit es als ideale Vorstufe für detailliertere Analysen (z.B. Ishikawa) fungiert.

    \item \textbf{Mind-Mapping:} Diese Methode ermöglicht eine hierarchische Gliederung der Einflussgrößen ausgehend vom Untersuchungsziel (Wurzel) über Haupt- zu Nebenparametern (Äste). Der entscheidende Vorteil für das Screening liegt in der Möglichkeit, \textit{Querbeziehungen} durch Verbindungslinien zwischen den Ästen zu visualisieren, wodurch Interdependenzen abseits der direkten Hierarchie offensichtlich werden \cite{Buzan.2010}.

    \item \textbf{Erweitertes Ishikawa-Diagramm:} Das klassische Ursache-Wirkungs - Diagramm (Fischgräten-Diagramm) strukturiert Parameter traditionell nach $6M$ (Mensch, Maschine, Material, Methode, Mitwelt, Messung). Für das heuristische Screening wird es dahingehend modifiziert, dass nicht nur statische Haupteffekte, sondern explizit \textbf{Interaktionen} durch \textit{Querverbindungen} zwischen den Ästen visualisiert werden (vgl. Abbildung~\ref{fig:ishikawa_interactions}) \cite{Arndt.2022,Daenzer.2002}.

    \item \textbf{Interdependenz-Netzwerke (Vernetztes Denken):} Für hochkomplexe Systeme bietet sich die Modellierung als gerichteter Graph an. Hierbei werden Parameter als Knoten und ihre Wirkbeziehungen als Kanten dargestellt \cite{Tittmann.2019}. Dies erlaubt nicht nur die Abbildung der Wirkrichtung (positiv/negativ), sondern auch die Integration zeitlicher Dynamiken und Intensitäten, was für die Modellierung von Degradationsprozessen vorteilhaft ist.

    \item \textbf{ABC-Analyse:} Zur Reduktion der Komplexität klassifiziert die ABC-Analyse die Parameter nach dem Pareto-Prinzip in Klassen hoher (A), mittlerer (B) und geringer (C) Relevanz. Dies dient als erster Filter, um den Fokus auf die vermuteten Haupttreiber der Lebensdauer zu lenken \cite{Montgomery.2020}.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.95\textwidth}
    % \import{plots/}{J22-arndt-Ishi.pdf_tex}
    \caption{Erweitertes Ishikawa-Diagramm zur Visualisierung von Interaktionen zwischen Einflussfaktoren (adaptiert nach \cite{Arndt.2022})}
    \label{fig:ishikawa_interactions}
\end{figure}

Die hierdurch erreichte Transparenz über die Vernetzung der Parameter bildet die notwendige Basis für den nächsten Schritt: Die Überführung der qualitativen Struktur in eine quantitative Priorisierung, um die finalen Faktoren für den Versuchsplan zu selektieren.

\subsection{Bewertungsmethoden (Decision Making)} \label{subsec:Decision}
Aufbauend auf der qualitativen Strukturierung der Einflussgrößen (vgl. Abschnitt \ref{subsec:Strukturierungsmethoden}) ist nun eine analytische Bewertung erforderlich, um die \textit{Vital Few} von den \textit{Trivial Many} zu separieren.
Ziel ist es, die gesammelten Parameter in eine Rangfolge zu bringen, die sowohl deren vermutete Relevanz für die Lebensdauer als auch deren Interaktionspotenzial widerspiegelt.
Hierfür eignen sich matrixbasierte Ansätze, die eine systematische Paarvergleichung erzwingen und subjektive Einschätzungen objektivierbar machen.
\subsubsection{Design-Structure-Matrix (\ac{DSM})} \label{subsubsec:dsm}
Die \ac{DSM} ist eine quadratische $\sym{n} \times \sym{n}$-Matrix, in der alle $\sym{n}$ identifizierten Systemparameter sowohl in den Zeilen als auch in den Spalten aufgetragen sind.
Ein Eintrag $\sym{y}_{\sym{idx_i}\sym{idx_j}}$ in der Matrix symbolisiert dabei eine gerichtete Abhängigkeit: Der Parameter in Zeile $\sym{idx_i}$ beeinflusst den Parameter in Spalte $\sym{idx_j}$.
Für das Screening im Kontext der Zuverlässigkeit wird die Matrix häufig um eine Zielgrößen-Spalte erweitert, um den direkten Einfluss auf die Lebensdauer $\sym{t}$ zu erfassen.
Die Bewertung kann auf zwei Detailebenen erfolgen:
\begin{itemize}
    \item \textbf{Binäre DSM:} Erfasst lediglich die Existenz einer Interaktion ($\sym{y}_{\sym{idx_i}\sym{idx_j}} \in \{0, 1\}$). Dies eignet sich für frühe Phasen mit geringem Detailwissen, um prinzipielle Vernetzungen aufzudecken.
    \item \textbf{Numerische DSM:} Gewichtet die Stärke des Einflusses, z.B. auf einer Skala von 0 (kein Einfluss) bis 3 (starker Einfluss). Dies erlaubt eine differenzierte Priorisierung.
\end{itemize}
Ein wesentlicher Vorteil der \ac{DSM} ist die Aufdeckung von Asymmetrien: Ein Parameter A kann Parameter B stark beeinflussen, ohne dass B signifikant auf A zurückwirkt ($\sym{y}_{\text{AB}}\neq\sym{y}_{\text{BA}}$).
Solche "aktiven" Parameter sind potenzielle Steuergrößen für den Versuchsplan.
Zudem ermöglicht die Matrix durch algorithmische Partitionierung (Clustering) das Identifizieren von Parametergruppen, die eng miteinander interagieren, was Hinweise auf physikalische Wirkmechanismen liefert \cite{Lindemann.2008}.
\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.8\textwidth}
    % \import{plots/}{J22-arndt-B-DSM.pdf_tex}
    \caption{Beispielhafte Darstellung einer binären DSM zur Identifikation von Interaktionen zwischen Systemparametern (adaptiert nach \cite{Arndt.2022})}
    \label{fig:dsm_example}
\end{figure}
\subsubsection{Grid-Analyse (Portfolio-Analyse)} \label{subsubsec:grid}
Die Grid-Analyse visualisiert die Ergebnisse der numerischen \ac{DSM} in einem zweidimensionalen Portfolio-Diagramm (vgl. Abbildung~\ref{fig:grid_analysis}).
Hierfür werden für jeden Parameter $\sym{idx_i}$ zwei Kennzahlen berechnet \cite{Mayers.1997}:
\begin{enumerate}
    \item \textbf{Aktivsumme (Active Sum):} Die Summe der Zeileneinträge ($\sum_{\sym{idx_j}} \sym{y}_{\sym{idx_i}\sym{idx_j}}$). Sie ist ein Maß dafür, wie stark der Parameter das Gesamtsystem treibt.
    \item \textbf{Passivsumme (Passive Sum):} Die Summe der Spalteneinträge ($\sum_{\sym{idx_i}} \sym{y}_{\sym{idx_i}\sym{idx_j}}$). Sie beschreibt, wie stark der Parameter selbst von anderen Größen beeinflusst wird (Reaktivität).
\end{enumerate}
Die Positionierung im Diagramm erlaubt eine Klassifizierung in vier Quadranten, aus denen sich direkte Handlungsempfehlungen für das \ac{DoE} ableiten lassen:
\begin{itemize}
    \item \textbf{Aktive Parameter (hohe Aktiv-, niedrige Passivsumme):} Diese Größen sind die idealen Steuerfaktoren ($\sym{x}$) für den Versuchsplan, da sie das System dominieren, ohne selbst instabil zu sein.
    \item \textbf{Kritische Parameter (hohe Aktiv- und Passivsumme):} Diese Faktoren sind stark vernetzt. Sie sind relevant für die Lebensdauer, bergen aber aufgrund ihrer Abhängigkeiten ein hohes Risiko für unerwünschte Wechselwirkungen. Sie müssen im Versuch besonders genau überwacht werden.
    \item \textbf{Passive Parameter (niedrige Aktiv-, hohe Passivsumme):} Diese Größen eignen sich weniger als Steuerfaktoren, sondern vielmehr als Indikatoren oder Antwortgrößen ($\sym{y}$), da sie empfindlich auf Änderungen im System reagieren.
    \item \textbf{Träge Parameter (niedrige Summen):} Diese Faktoren spielen eine untergeordnete Rolle und können im Screening oft vernachlässigt oder als Konstanten fixiert werden.
\end{itemize}Um die Unsicherheit heuristischer Schätzungen abzubilden, kann die Grid-Analyse um Konfidenz-Vektoren erweitert werden.
Dabei geben Experten für jede Bewertung an, ob diese auf gesichertem Wissen (Daten, Literatur) oder Intuition beruht.
Große Differenzen zwischen \textit{gesicherter} und \textit{intuitiver} Position im Grid weisen auf Wissenslücken hin, die zwingend durch experimentelle Voruntersuchungen geschlossen werden müssen, bevor der Parameter in ein aufwendiges \ac{L-DoE} aufgenommen wird.
\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.8\textwidth}
    % \import{plots/}{J22-arndt-Grid.pdf_tex}
    \caption{Grid-Analyse zur Klassifizierung von Parametern in aktive, kritische, passive und träge Faktoren}
    \label{fig:grid_analysis}
\end{figure}
\subsubsection{Finale Parameter-Diskussion}
Die Ergebnisse aus \ac{DSM} und Grid-Analyse dienen als Entscheidungsgrundlage für die finale Selektion der Versuchs-Faktoren.
In diesem Diskurs müssen die heuristischen Erkenntnisse gegen die harten Restriktionen des Versuchsplans (Budget, Machbarkeit, Messbarkeit) abgewogen werden.
Es gilt, einen Kompromiss zu finden zwischen der vollständigen Abbildung aller wirksamen Mechanismen (Modellgüte) und der Reduktion auf eine handhabbare Anzahl an Faktoren (Effizienz).
Faktoren, die als relevant identifiziert wurden, aber aus Budgetgründen nicht variiert werden können, müssen explizit als Konstanten dokumentiert oder als Noise-Faktoren in einer Robustheitsbetrachtung berücksichtigt werden.

\section{Randbedingungen in der Parameterauswahl für die Zuverlässigkeitsmodellierung} \label{sec:screening_randbedingungen}
Die Anwendung der oben genannten Methoden muss im Kontext der Lebensdaueranalyse spezifische Randbedingungen berücksichtigen, die sich fundamental von der klassischen Robustheitsoptimierung unterscheiden.

\subsection{Unterscheidung: Robustheit vs. Zuverlässigkeit}
Ein häufiges Missverständnis im Screening ist die Gleichsetzung von initialer Performance-Streuung mit Lebensdauer-Streuung.
Wie in Abbildung~\ref{fig:degradation_scheme} dargestellt, betrachtet die klassische Robustheitsanalyse nach \textcite{Klein.2014} im Verständnis von \textit{Taguchi}/\textit{Shainin} oft nur die Verteilung der Systemantwort zum Zeitpunkt $\sym{t}=0$ (Bereich A).
Die Zuverlässigkeitstechnik fokussiert jedoch auf die \textbf{Degradation} über die Zeit (Bereich B).
Ein Faktor, der die initiale Performance kaum beeinflusst (z.B. Korrosionsschutzschicht-Dicke), kann für die Lebensdauer $\sym{t}$ dominant sein.
Heuristisches Screening für \ac{L-DoE} muss daher explizit Parameter priorisieren, die \textit{zeitabhängige} Schädigungsmechanismen (Verschleiß, Alterung, Ermüdung) treiben, selbst wenn sie initial "inaktiv" erscheinen.

\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.9\textwidth}
    % \import{plots/}{J22-arndt-degra.pdf_tex}
    \caption{Abgrenzung zwischen initialer Performance-Verteilung (A) und zeitabhängiger Degradation (B) im Screening-Prozess}
    \label{fig:degradation_scheme}
\end{figure}

\subsection{Anforderungen aus dem Versuchsplan (L-DoE)}
Die im heuristischen Prozess ausgewählten Faktoren müssen später im statistischen Versuchsplan (\ac{DoE}) verarbeitet werden. Daraus ergeben sich harte Restriktionen für die Auswahl:
\begin{itemize}
    \item \textbf{Einstellbarkeit (Controllability):} Nur Parameter, die im Versuch aktiv und präzise auf verschiedene Niveaus (Levels) eingestellt werden können, qualifizieren sich als Faktoren. Nicht steuerbare Größen müssen als Noise oder Co-Faktoren behandelt werden.
    \item \textbf{Beschleunigbarkeit:} Für \ac{ALT} müssen Faktoren gewählt werden, die eine physikalische Beschleunigung der Schädigung ermöglichen (z.\,B. Temperatur, Spannung), ohne den Fehlermechanismus zu verändern.
    \item \textbf{Kosten und Komplexität:} Da der Stichprobenumfang bei voll-faktoriellen Plänen mit $\sym{n} \propto \sym{m}^{\sym{k}}$ wächst, zwingt die Ökonomie zur drastischen Reduktion von $\sym{k}$. Das Screening muss daher einen "Cut-Off" definieren, der oft bei $\sym{k} \le 5 \dots 7$ Faktoren liegt.
    \item \textbf{Design Resolution (Auflösung):} Wenn viele Faktoren im Screening verbleiben, müssen fraktionelle Pläne (Teilfaktoriell) genutzt werden. Das Screening muss vorab klären, welche Interaktionen physikalisch plausibel sind, um eine geeignete Auflösung (Resolution III, IV oder V) zu wählen und Aliasing von Haupteffekten mit wichtigen Wechselwirkungen zu vermeiden.
\end{itemize}

\section{Vorgehen zum heuristischen Screening für die Zuverlässigkeitsmodellierung} \label{sec:screening_vorgehen}
Basierend auf der Analyse der Methoden und Randbedingungen wird folgendes prozedurales Vorgehen für das Parameter-Screening in der Zuverlässigkeitsmodellierung vorgeschlagen (vgl. Abbildung~\ref{fig:screening_procedure}).
Dieser Ansatz stellt eine "Firewall" vor den eigentlichen kostenintensiven Lebensdauerversuch dar.

\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.95\textwidth}
    % \import{plots/}{J22-arndt-Procedure.pdf_tex}
    \caption{Methodischer Ablauf des heuristischen Screenings als Vorstufe zum L-DoE}
    \label{fig:screening_procedure}
\end{figure}

\subsection*{Phase I: Systemanalyse und Failure-Mode-Definition}
Der Prozess beginnt nicht mit den Parametern, sondern mit dem Fehlermechanismus.
Basierend auf dem \ac{FBD} (Abschnitt~\ref{sec:screening_identifikation}) wird definiert, welcher spezifische \textbf{Failure Mode} untersucht werden soll (z.\,B. "Zahnbruch" vs. "Abrieb" bei einem Riemen).
Unterschiedliche Fehlermodi werden oft von unterschiedlichen Parametersets getrieben.
Eine Vermischung führt zu Rauschen in den Daten.

\subsection*{Phase II: Heuristische Filterung}
Im zweiten Schritt wird der Parameter-Pool durch die in Abschnitt~\ref{sec:screening_kreativ} vorgestellten Methoden (z.\,B. Ishikawa + Grid-Analyse) gefiltert.
Kritisch ist hier die Bewertung der \textbf{Interaktionsdichte}.
Faktoren, die im Ishikawa-Diagramm oder der \ac{DSM} viele Vernetzungen aufweisen (hohe Aktivsumme), werden priorisiert, da sie wahrscheinlich Katalysatoren für Degradationsprozesse sind.
Das Ergebnis ist ein Ranking der Faktoren nach ihrer vermuteten Relevanz für die Lebensdauer.

\subsection*{Phase III: Test-Design-Matching}
Im letzten Schritt wird die Top-Liste der Faktoren gegen die Restriktionen des gewählten \ac{DoE}-Plans (siehe Kapitel 3 und Abschnitt~\ref{sec:screening_randbedingungen}) abgeglichen.
\begin{itemize}
    \item Ist die Anzahl $\sym{k}$ kompatibel mit dem Budget für $\sym{n}$ Versuche?
    \item Sind die Faktoren physikalisch unabhängig voneinander einstellbar (Orthogonalität)?
    \item Erlauben die gewählten Stufenabstände eine signifikante Änderung der Lebensdauer (Power $> 80\%$)?
\end{itemize}
Nur Faktoren, die diesen Filter passieren, werden in das finale \ac{L-DoE}-Modell aufgenommen.
Parameter, die als "mittelwichtig" eingestuft wurden aber aus Budgetgründen entfallen, werden als konstante Randbedingungen dokumentiert oder als Noise-Faktoren in Robustheits-Analysen ausgelagert.

\section{Zusammenfassung}
Das in diesem Kapitel vorgestellte heuristische Screening schließt die Lücke zwischen der qualitativen Systemanalyse und der quantitativen Versuchsplanung.
Indem Expertenwissen strukturiert genutzt wird (z.\,B. durch \ac{DSM} und erweiterte Ishikawa-Diagramme), kann die Anzahl der Versuchs-Faktoren $\sym{k}$ drastisch reduziert werden, ohne relevante Interaktionen zu übersehen.
Entscheidend ist dabei der Perspektivwechsel von der initialen Performance-Streuung hin zur zeitabhängigen Degradation.
Dieses Vorgehen ermöglicht es, die in Kapitel 3 diskutierten effizienten Versuchspläne (wie CCD oder OMARS) überhaupt erst anwendbar zu machen, da diese nur mit einer begrenzten Anzahl an Faktoren ($\sym{k} \approx 3 \dots 7$) wirtschaftlich operieren.
Die methodische Vorarbeit des Screenings ist somit der Hebel für die Effizienz des gesamten Lebensdauerversuchs.