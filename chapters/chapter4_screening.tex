%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Kapitel 4 - Parameter-Screening %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Parameter-Screening für multifaktorielle Lebensdauertests} \label{chap:screening}

Die in Kapitel~\ref{chap:ansatz} hergeleitete Notwendigkeit effizienter Testdesigns setzt voraus, dass die Anzahl der zu untersuchenden Faktoren $\sym{k}$ auf ein handhabbares Maß begrenzt ist.
Da die Komplexität und der Versuchsumfang exponentiell mit der Anzahl der Faktoren steigen (vgl. Gleichung~\ref{eq:ffvp_n}), ist eine präzise Vorselektion der Einflussgrößen entscheidend.
Klassische Ansätze der Versuchsplanung setzen hierfür oft auf experimentelle Screening-Pläne.
Im Kontext der Lebensdauererprobung führen diese jedoch zu einem Paradoxon: Um experimentell zu prüfen, ob ein Parameter die Lebensdauer beeinflusst, müssten gleichermaßen bei konventionellen Screeningdesigns (z.B. $2^{\sym{k}-\sym{p_f}}$ Designs, Plackett-Burman-Designs) sowie modernen \acp{RSD} (z.B. \ac{OMARS}-Designs) bereits zeitintensive \ac{EoL}-Tests durchgeführt werden, was den Effizienzvorteil des Screenings zunichtemacht.

Dieses Kapitel stellt daher einen effizienten methodischen Ansatz zum \textbf{heuristischen Screening} vor.
Ziel ist es, basierend auf Expertenwissen und systematischer Analyse eine qualitative Reduktion des Parameterraums vorzunehmen, \textit{bevor} physische Versuche gestartet werden \cite{Arndt.2023c}.
Dabei liegt der Fokus explizit auf der Unterscheidung zwischen bloßer Robustheit (zum Zeitpunkt $\sym{t}=0$) und echter Zuverlässigkeit (über die Zeit $\sym{t}>0$).
Aus der Perspektive der Zeitdomäne ist die differenzierte Klassifizierung der Einflussfaktoren für die Konzeption zuverlässigkeitstechnischer Untersuchungen von entscheidender Bedeutung.
Schließlich sind stochastische Degradationspfade entsprechend Abschnitt~\ref{subsec:begriffezuv} und die daraus resultierende Überlebenswahrscheinlichkeit $\sym{R}(\sym{t})$ nicht statisch zu betrachten, sondern zeitvarianten Interaktionsstrukturen und einer sich verschiebenden Effekthierarchie unterlegen.
Folglich kann das Parameterset, welches das Systemverhalten in fortgeschrittenen Phasen des Lebensdauerzyklus determiniert, signifikant von jenen Faktoren divergieren, die lediglich die initiale Performanceverteilung des Systems bei $\sym{t}=0$ dominieren.
Die Auswahl der relevanten Kovariaten ist somit inhärent dem Einfluss der Zeit ausgesetzt.
Um dieser Dynamik gerecht zu werden, synergiert der vorgestellte Ansatz teils bestens etablierte Kreativtechniken (z.B. Brainstorming, Fehlerbaum-Analysen - engl. \ac{FTA}, Ishikawa-Diagramme) mit strukturierten Bewertungswerkzeugen (z.B. \ac{DSM}, Grid-Analyse), um eine belastbare Identifikation und Priorisierung der kritischen Einflussgrößen zu gewährleisten.

\section{Identifikation potenzieller Einflussgrößen} \label{sec:screening_identifikation}
Die Basis eines jeden Screenings bildet die vollständige Erfassung aller potenziellen Einflussgrößen.
Um eine lückenlose Identifikation zu gewährleisten, ist eine strukturierte Systemanalyse unerlässlich, wie sie in der Zuverlässigkeitstechnik nach \textcite{Bertsche.2022} etabliert ist.
Ein zentrales Werkzeug hierfür ist das \textbf{Funktionsblockdiagramm}, engl. \textbf{\ac{FBD}} \cite{Lindemann.2008,Krallmann.2013,Gundlach.2004}.
Es abstrahiert das technische System auf seine Ein- und Ausgangsgrößen, klassifiziert nach den Flussgrößen \textit{Energie}, \textit{Stoff} und \textit{Signal} (vgl. Abbildung~\ref{fig:fbd_structure}) \cite{Pahl.2007}.
Innerhalb der Systemgrenzen werden Haupt- und Nebenfunktionen definiert, deren Nichterfüllung direkt zu potenziellen Ausfallmechanismen führt.
\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.9\textwidth}
    % \import{plots/}{J22-arndt-fu-subfu.pdf_tex}
    \caption{Funktionsstruktur mit Haupt-, Neben- und Teilfunktionen zur Identifikation von Einflussgrößen (nach \textcite{Wallace.2007})}
    \label{fig:fbd_structure}
\end{figure}
Zur initialen Sammlung der Parameter (Informationsbeschaffung) eignen sich, aufbauend auf dem \ac{FBD}, entsprechend \textcite{Montgomery.2020b,Bruckner.2019} klassische Methoden des Qualitätsmanagements (\ac{Q7} and \ac{M7}) sowie etliche Kreativtechniken:
\begin{itemize}
    \item \textbf{Literaturrecherche:} Analyse bestehender Ausfallmodi und physikalischer Wirkmechanismen (z.B. Arrhenius, Wöhler) aus vergleichbaren Anwendungen aber auch simulativen Untersuchungen (\ac{FEA}) \cite{Breiing.1997}.
    \item \textbf{Brainstorming} bzw. \textbf{ABC-Brainstorming} ermöglichen es interdisziplinären Expertenteams, intuitives Erfahrungswissen zu explizieren \cite{Daenzer.2002,Mayers.1997}.
    \item \textbf{Delphi-Methode:} Durch mehrstufige, anonymisierte Befragungen von Experten können subjektive Einschätzungen objektiviert und Konsens über potenzielle Einflussgrößen erzielt werden \cite{Daenzer.2002}.
    \item \textbf{Morphologische Analyse:} Durch die Zerlegung des Systems in Teilfunktionen und die Variation von Lösungsprinzipien werden systematisch konstruktive Einflussparameter aufgedeckt \cite{Albers.2005,Thompson.1999}.
\end{itemize}
Das Ergebnis dieses Schrittes ist eine unsortierte, aber möglichst vollständige Liste (Parameter-Pool) aller Größen, die potenziell auf das System einwirken.

\section{Kreativmethoden zum Auswahlprozesse im Parameter-Screening} \label{sec:kreativmethoden}
{Kreativmethoden zum Auswahlprozess im Parameter-Screening} \label{sec:screening_kreativ}
Nach der Identifikation muss der Parameter-Pool zunächst strukturiert und anschließend bewertet werden, um die vitalen Einflussgrößen (\textit{vital few}) von den trivialen (\textit{trivial many}) zu trennen, vergleiche \textcite{Arndt.2023c}.
Insbesondere basierend auf Arbeiten von \textcite{Gundlach.2004,Kremer.2018b,Mayers.1997} werden im Folgenden geeignete Methoden vorgestellt, die sich für das heuristische Screening im Kontext von zeitvarianten Parametersets in der Lebensdaueranalyse eignen und darüber hinaus auf Randbedingungen der Versuchsplanung Rücksicht nehmen.
\subsection{Strukturierungsmethoden} \label{subsec:Strukturierungsmethoden}
Nachdem durch die vorangegangenen Schritte der Informationsbeschaffung eine möglichst vollständige Sammlung aller potenziellen Systemparameter, Inputs und Outputs generiert wurde, bedarf es einer systematischen Strukturierung auf Basis eines vertieften Systemverständnisses.
Dieser Schritt darf sich nicht auf eine reine Clusterung in Parametergruppen beschränken.
Vielmehr gilt es, die \textit{gegenseitigen Beeinflussungen} der Größen zu identifizieren und zu offenbaren.
Insbesondere für die Lebensdaueranalyse stellt dies einen entscheidenden Mehrwert dar, der im Einklang mit den Prinzipien des \ac{L-DoE} steht \cite{Montgomery.2020,Kremer.2021}: Phänomene wie Alterungseffekte oder die zeitvariante Änderung von Materialeigenschaften sind physikalisch oft nicht trivial durch Einzelgrößen beschreibbar, sondern resultieren maßgeblich aus Interaktionen (vgl. Abbildung~\ref{fig:degradation_scheme}).
Um diese komplexen, teils zeitabhängigen Zusammenhänge für die weitere Selektion greifbar zu machen, eignen sich primär grafische Methoden, die über die reine Auflistung hinausgehen:

\begin{itemize}
    \item \textbf{Affinitätsdiagramm:} Als Werkzeug der \textit{M7} dient es der thematischen Clusterung der oft unstrukturierten Ergebnisse aus Brainstorming-Sessions \cite{Bruckner.2019}. Es ordnet Parameter übergeordneten Kategorien zu und deckt erste logische Gruppierungen auf, womit es als ideale Vorstufe für detailliertere Analysen (z.B. Ishikawa) fungiert.

    \item \textbf{Mind-Mapping:} Diese Methode ermöglicht eine hierarchische Gliederung der Einflussgrößen ausgehend vom Untersuchungsziel (Wurzel) über Haupt- zu Nebenparametern (Äste). Der entscheidende Vorteil für das Screening liegt in der Möglichkeit, \textit{Querbeziehungen} durch Verbindungslinien zwischen den Ästen zu visualisieren, wodurch Interdependenzen abseits der direkten Hierarchie offensichtlich werden \cite{Buzan.2010}.

    \item \textbf{Erweitertes Ishikawa-Diagramm:} Das klassische Ursache-Wirkungs - Diagramm (Fischgräten-Diagramm) strukturiert Parameter traditionell nach $6M$ (Mensch, Maschine, Material, Methode, Mitwelt, Messung). Für das heuristische Screening wird es dahingehend modifiziert, dass nicht nur statische Haupteffekte, sondern explizit \textbf{Interaktionen} durch \textit{Querverbindungen} zwischen den Ästen visualisiert werden (vgl. Abbildung~\ref{fig:ishikawa_interactions}) \cite{Arndt.2022,Daenzer.2002}.

    \item \textbf{Interdependenz-Netzwerke (Vernetztes Denken):} Für hochkomplexe Systeme bietet sich die Modellierung als gerichteter Graph an. Hierbei werden Parameter als Knoten und ihre Wirkbeziehungen als Kanten dargestellt \cite{Tittmann.2019}. Dies erlaubt nicht nur die Abbildung der Wirkrichtung (positiv/negativ), sondern auch die Integration zeitlicher Dynamiken und Intensitäten, was für die Modellierung von Degradationsprozessen vorteilhaft ist.

    \item \textbf{ABC-Analyse:} Zur Reduktion der Komplexität klassifiziert die ABC-Analyse die Parameter nach dem Pareto-Prinzip in Klassen hoher (A), mittlerer (B) und geringer (C) Relevanz. Dies dient als erster Filter, um den Fokus auf die vermuteten Haupttreiber der Lebensdauer zu lenken \cite{Montgomery.2020}.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.95\textwidth}
    % \import{plots/}{J22-arndt-Ishi.pdf_tex}
    \caption{Erweitertes Ishikawa-Diagramm zur Visualisierung von Interaktionen zwischen Einflussfaktoren (adaptiert nach \cite{Arndt.2022})}
    \label{fig:ishikawa_interactions}
\end{figure}

Die hierdurch erreichte Transparenz über die Vernetzung der Parameter bildet die notwendige Basis für den nächsten Schritt: Die Überführung der qualitativen Struktur in eine quantitative Priorisierung, um die finalen Faktoren für den Versuchsplan zu selektieren.

\subsection{Bewertungsmethoden (Decision Making)} \label{subsec:Decision}
Aufbauend auf der qualitativen Strukturierung der Einflussgrößen (vgl. Abschnitt \ref{subsec:Strukturierungsmethoden}) ist nun eine analytische Bewertung erforderlich, um die \textit{vital few} von den \textit{trivial many} zu separieren.
Ziel ist es, die gesammelten Parameter in eine Rangfolge zu bringen, die sowohl deren vermutete Relevanz für die Lebensdauer als auch deren Interaktionspotenzial widerspiegelt.
Hierfür eignen sich matrixbasierte Ansätze, die eine systematische Paarvergleichung erzwingen und subjektive Einschätzungen objektivierbar machen.
\subsubsection{Design-Structure-Matrix (\ac{DSM})} \label{subsubsec:dsm}
Die \ac{DSM} ist eine quadratische $\sym{n} \times \sym{n}$-Matrix, in der alle $\sym{n}$ identifizierten Systemparameter sowohl in den Zeilen als auch in den Spalten aufgetragen sind.
Ein Eintrag $\sym{y}_{\sym{idx_i}\sym{idx_j}}$ in der Matrix symbolisiert dabei eine gerichtete Abhängigkeit: Der Parameter in Zeile $\sym{idx_i}$ beeinflusst den Parameter in Spalte $\sym{idx_j}$ \cite{Kremer.2018b,Lindemann.2008}.
Für das Screening im Kontext der Zuverlässigkeit wird die Matrix häufig um eine Zielgrößen-Spalte erweitert, um den direkten Einfluss auf die Lebensdauer $\sym{t}$ zu erfassen.
Die Bewertung kann auf zwei Detailebenen erfolgen:
\begin{itemize}
    \item \textbf{Binäre DSM:} Erfasst lediglich die Existenz einer Interaktion ($\sym{y}_{\sym{idx_i}\sym{idx_j}} \in \{0, 1\}$). Dies eignet sich für frühe Phasen mit geringem Detailwissen, um prinzipielle Vernetzungen aufzudecken.
    \item \textbf{Numerische DSM:} Gewichtet die Stärke des Einflusses, z.B. auf einer Skala von 0 (kein Einfluss) bis 3 (starker Einfluss). Dies erlaubt eine differenzierte Priorisierung.
\end{itemize}
Ein wesentlicher Vorteil der \ac{DSM} ist die Aufdeckung von Asymmetrien: Ein Parameter A kann Parameter B stark beeinflussen, ohne dass B signifikant auf A zurückwirkt ($\sym{y}_{\text{AB}}\neq\sym{y}_{\text{BA}}$).
Solche \textit{aktiven} Parameter sind potenzielle Steuergrößen für den Versuchsplan \cite{Kremer.2021,Arndt.2023c}.
Zudem ermöglicht die Matrix durch algorithmische Partitionierung (Clustering) das Identifizieren von Parametergruppen, die eng miteinander interagieren, was Hinweise auf physikalische Wirkmechanismen liefert \cite{Lindemann.2008}.
\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.8\textwidth}
    % \import{plots/}{J22-arndt-B-DSM.pdf_tex}
    \caption{Beispielhafte Darstellung einer binären DSM zur Identifikation von Interaktionen zwischen Systemparametern (adaptiert nach \cite{Arndt.2022})}
    \label{fig:dsm_example}
\end{figure}
\subsubsection{Grid-Analyse (Portfolio-Analyse)} \label{subsubsec:grid}
Die Grid-Analyse visualisiert die Ergebnisse der numerischen \ac{DSM} in einem zweidimensionalen Portfolio-Diagramm (vgl. Abbildung~\ref{fig:grid_analysis}).
Hierfür werden für jeden Parameter $\sym{idx_i}$ zwei Kennzahlen berechnet \cite{Mayers.1997}:
\begin{enumerate}
    \item \textbf{Aktivsumme (Active Sum):} Die Summe der Zeileneinträge ($\sum_{\sym{idx_j}} \sym{y}_{\sym{idx_i}\sym{idx_j}}$). Sie ist ein Maß dafür, wie stark der Parameter das Gesamtsystem treibt.
    \item \textbf{Passivsumme (Passive Sum):} Die Summe der Spalteneinträge ($\sum_{\sym{idx_i}} \sym{y}_{\sym{idx_i}\sym{idx_j}}$). Sie beschreibt, wie stark der Parameter selbst von anderen Größen beeinflusst wird (Reaktivität).
\end{enumerate}
Die Positionierung im Diagramm erlaubt eine Klassifizierung in vier Quadranten, aus denen sich direkte Handlungsempfehlungen für das \ac{DoE} ableiten:
\begin{itemize}
    \item \textbf{Aktive Parameter (hohe Aktiv-, niedrige Passivsumme):} Diese Größen qualifizieren sich als ideale Steuerfaktoren ($\sym{x}$) für den Versuchsplan, da sie das System dominieren, ohne selbst instabil zu sein.
    \item \textbf{Kritische Parameter (hohe Aktiv- und Passivsumme):} Diese Faktoren weisen eine starke Vernetzung auf. Sie sind relevant für die Lebensdauer, bergen aber aufgrund ihrer Abhängigkeiten ein hohes Risiko für unerwünschte Wechselwirkungen. Ihre Überwachung im Versuch ist von besonderer Bedeutung.
    \item \textbf{Passive Parameter (niedrige Aktiv-, hohe Passivsumme):} Diese Größen eignen sich primär als Indikatoren oder Antwortgrößen ($\sym{y}$), da sie empfindlich auf Änderungen im System reagieren, während ihre Eignung als Steuerfaktoren als gering einzustufen ist.
    \item \textbf{Träge Parameter (niedrige Summen):} Diese Faktoren spielen eine untergeordnete Rolle und lassen sich im Screening oft vernachlässigen oder als Konstanten fixieren.
\end{itemize}
Zur Abbildung der Unsicherheit heuristischer Schätzungen ist eine Erweiterung der Grid-Analyse um Konfidenz-Vektoren möglich \cite{Arndt.2023c}.
Hierbei geben Experten für jede Bewertung an, ob diese auf gesichertem Wissen (Daten, Literatur) oder Intuition beruht.
Große Differenzen zwischen \textit{gesicherter} und \textit{intuitiver} Position im Grid indizieren Wissenslücken, deren Schließung durch experimentelle Voruntersuchungen vor der Aufnahme des Parameters in ein aufwendiges \ac{L-DoE} erforderlich ist.
\begin{figure}[htbp]
    \centering\def\svgwidth{0.8\textwidth}
    % \import{plots/}{J22-arndt-Grid.pdf_tex}
    \caption{Grid-Analyse zur Klassifizierung von Parametern in aktive, kritische, passive und träge Faktoren}
    \label{fig:grid_analysis}
\end{figure}

\subsection{Finale Parameter-Diskussion}
Die Ergebnisse aus \ac{DSM} und Grid-Analyse bilden die Entscheidungsgrundlage für die finale Selektion der Versuchs-Faktoren \cite{Arndt.2023c}.
In diesem Diskurs erfolgt eine Abwägung der heuristischen Erkenntnisse gegen die harten Restriktionen des Versuchsplans (Budget, Planungsumfang, Messbarkeit).
Ziel ist ein Kompromiss zwischen der vollständigen Abbildung aller wirksamen Mechanismen (Modellgüte) und der Reduktion auf eine handhabbare Anzahl an Faktoren (Effizienz).
Als relevant identifizierte, aber aus Budgetgründen nicht variierbare Faktoren sind explizit als Konstanten zu dokumentieren oder als Noise-Faktoren in einer Robustheitsbetrachtung zu berücksichtigen.
\section{Randbedingungen in der Parameterauswahl für die Zuverlässigkeitsmodellierung} \label{sec:screening_randbedingungen}
Die Anwendung der oben genannten Methoden muss im Kontext der Lebensdaueranalyse spezifische Randbedingungen berücksichtigen, die sich fundamental von der klassischen Robustheitsoptimierung unterscheiden \cite{Gundlach.2004,Mayers.1997,Klein.2011}.

\subsection{Unterscheidung: Robustheit vs. Zuverlässigkeit}
Ein häufiges Missverständnis im Screening ist die Gleichsetzung von initialer Streuung der Produktperformance mit Lebensdauerstreuung.
Wie in Abbildung~\ref{fig:degradation_scheme} dargestellt, betrachtet die klassische Robustheitsanalyse nach \textcite{Klein.2014} im Verständnis von \textit{Taguchi}/\textit{Shainin} oft nur die Verteilung der Systemantwort zum Zeitpunkt $\sym{t}=0$.
Die Zuverlässigkeitstechnik fokussiert jedoch auf die \textbf{Degradation} über die Zeit.
Faktoren, die initial kaum Einfluss auf die Performance haben (z.B. Materialalterung, Verschleiß, Wechselwirkungen), können im Zeitverlauf dominante Treiber für Ausfallmechanismen werden.
Heuristisches Screening für \ac{L-DoE} muss daher explizit Parameter priorisieren, die \textit{zeitabhängige} Schädigungsmechanismen  treiben, selbst wenn sie \textit{initial inaktiv} erscheinen.
\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.9\textwidth}
    % \import{plots/}{J22-arndt-degra.pdf_tex}
    \caption{Abgrenzung zwischen initialer Performance-Verteilung (A) und zeitabhängiger Degradation (B) im Screening-Prozess}
    \label{fig:degradation_scheme}
\end{figure}

\subsection{Anforderungen aus dem Versuchsplan (L-DoE)} \label{subsec:anforderungen}
Die im heuristischen Prozess ausgewählten Faktoren werden darauffolgend im statistischen Versuchsplan (\ac{DoE}) schließlich verarbeitet.
Daraus ergeben sich zunächst harte Restriktionen für die Auswahl:
\begin{itemize}
    \item \textbf{Einstell- und Regelbarkeit:} Nur Parameter, die im Versuch aktiv und präzise auf verschiedene Stufen eingestellt werden können, qualifizieren sich als Faktoren. Nicht steuerbare Größen lassen sich sonst in \textit{Noise} oder \textit{Co-Faktoren} einordnen.
    \item \textbf{Beschleunigbarkeit:} Für \ac{ALT} werden schließlich nur Faktoren gewählt, die eine physikalische Beschleunigung der Schädigung ermöglichen (z.B. Temperatur, mechanische Spannung), ohne den Fehlermechanismus zu verändern.
    \item \textbf{Kosten und Komplexität:} Da der Stichprobenumfang bei voll-faktoriellen Plänen mit $\sym{n} \propto {\sym{m}\cdot\sym{N}}^{\sym{k}}$ wächst, vergleiche Abschnitte~\ref{subsec:pläne},\ref{subsec:strategie}, zwingt die Ökonomie zur drastischen Reduktion von $\sym{k}$. Gleiches Verhalten zeigt sich wie schon erwähnt auch bei konventionellen und modernisierten Algorithmen von \acp{RSD}. Das heuristische Screening definiert bestenfalls also ein wirtschaftlich abbildbares Maximum an umsetzbaren Faktoren $\sym{k}_{\max} \le 2 \dots 4$, vgl. \cite{Montgomery.2020,Siebertz.2017}.
    \item \textbf{Design Resolution (Auflösung):} Für den Fall, dass ultimativ dennoch viele vermeintlich relevante Faktoren aus dem Screening-Prozess resultieren, verbleiben nur Screening-Designs für die weitere experimentell empirische Analyse. Das Screening muss vorab klären, welche Interaktionen physikalisch plausibel sind, um eine geeignete Auflösung (Resolution III, IV oder V) oder Konfiguration von Screening-\acp{RSD} zu wählen und Aliasing von Haupteffekten mit wichtigen Wechselwirkungen zu minimieren bzw. zu vermeiden.
\end{itemize}

Mit den genannten Anforderungen zur methodischen Anwendung von \ac{L-DoE} ermöglichen schließlich die in Abschnitt~\ref{sec:screening_kreativ} identifizierten heuristischen Methoden für das Parameter-Screening ein strukturiertes Vorgehen zur effizienten Auswahl relevanter Einflussgrößen \cite{Arndt.2023c}.


\section{Vorgehen zum heuristischen Screening für die Zuverlässigkeitsmodellierung} \label{sec:screening_vorgehen}
Basierend auf der Analyse der Methoden und Randbedingungen wird in Anlehnung an \textcite{Arndt.2023c} folgendes prozedurales Vorgehen für das Parameter-Screening in der Zuverlässigkeitsmodellierung vorgeschlagen - vergleiche auch Abbildung~\ref{fig:screening_procedure}:.
Dieser Ansatz fungiert als methodische Barriere vor dem eigentlichen ressourcenintensiven Lebensdauerversuch, um die Effizienz der Datenerhebung zu maximieren.

\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.95\textwidth}
    % \import{plots/}{J22-arndt-Procedure.pdf_tex}
    \caption{Methodischer Ablauf des heuristischen Screenings als Vorstufe zum L-DoE}
    \label{fig:screening_procedure}
\end{figure}

\subsection{\textit{Phase I}: Systemanalyse und Fehlermechanismen}
Der Prozess initiiert nicht mit der isolierten Betrachtung von Parametern, sondern mit der Identifikation des relevanten Ausfallmechanismus.
Basierend auf dem \ac{FBD} (Abschnitt~\ref{sec:screening_identifikation}) erfolgt die Definition des spezifischen \textbf{Failure Mode} (z.B. Zahnbruch vs. Abrieb bei einem Riemen).
Da unterschiedliche Fehlermodi in der Regel von divergenten Parametersets getrieben werden, führt eine Vermischung unweigerlich zu Rauschen in den Daten und ist zu vermeiden.

\subsection{\textit{Phase II}: Heuristische Parameterassessment und Interaktionsanalyse}
Im zweiten Schritt unterliegt der Parameter-Pool einer Filterung durch die in Abschnitt~\ref{sec:screening_kreativ} vorgestellten Methoden (z.B. Ishikawa-Diagramm in Kombination mit Grid-Analyse).
\textcite{Arndt.2023c} stellen hierzu durch Bewertung der Eignung der Methoden im Kontext der Lebensdaueranalyse fest, dass vornehmlich die Kombination aus erweitertem Ishikawa-Diagramm (zur Visualisierung von Interaktionen) und \ac{DSM} (zur quantitativen Bewertung der Vernetzung) eine belastbare Grundlage für die Priorisierung der Faktoren darstellt.
Kritisch ist hierbei die Bewertung der Interaktionsdichte in Bezug auf die Lebensdauer als Zielgröße.
Faktoren, die im Ishikawa-Diagramm oder der \ac{DSM} eine hohe Vernetzung aufweisen (korrespondierend mit einer hohen Aktivsumme), erfahren eine Priorisierung, da sie mit hoher Wahrscheinlichkeit - insbesondere wechselwirkend über jedenfalls Abschnitte der Lebensdauer - als Katalysatoren für Degradationsprozesse fungieren.
Das Ergebnis dieses Prozessschrittes ist eine hierarchische Ordnung der Faktoren nach ihrer vermuteten Relevanz für die Lebensdauer.

\subsection{\textit{Phase III}: Abgleich mit dem Versuchsdesign}
Im finalen Schritt erfolgt der Abgleich der priorisierten Faktorenliste mit den Restriktionen des gewählten \ac{L-DoE} (vgl. Abschnitt~\ref{sec:forschungsfragen} sowie Abschnitt~\ref{subsec:anforderungen}).
Hierbei sind folgende Prüffragen essenziell:
\begin{itemize}
    \item Korrespondiert die Anzahl der Faktoren $\sym{k}$ mit dem verfügbaren Budget für $\sym{n}$ Versuche?
    \item Ist die physikalische Unabhängigkeit der Faktoreinstellung (Orthogonalität) gewährleistet?
    \item Ermöglichen die gewählten Stufenabstände eine signifikante, detektierbare Änderung der Lebensdauer (Power $> 80\%$), vgl. Abschnitt~\ref{subsec:begriffedoe}?
\end{itemize}
Lediglich Faktoren, die diesen Filter passieren, werden in das finale \ac{L-DoE}-Modell integriert.
Parameter, die als relevant klassifiziert wurden, jedoch aus Budgetgründen entfallen, sind als konstante Randbedingungen zu dokumentieren oder als Noise-Faktoren in Robustheitsanalysen auszulagern.

Das Resultat dieses dreistufigen Vorgehens ist eine kondensierte Parametermenge, die das Optimum zwischen notwendigem Informationsgehalt und vertretbarem experimentellem Aufwand repräsentiert.
Wie in Abbildung~\ref{fig:screening_procedure_volume} visualisiert, wird das Volumen der zu betrachtenden Einflussgrößen von der initialen Systemanalyse (Gesamtmenge) über die heuristische Bewertung bis hin zum finalen Design-Matching kontinuierlich auf das für das \ac{L-DoE} essenzielle Maß verdichtet.

\begin{figure}[htbp]
    \centering
    \def\svgwidth{0.95\textwidth}
    % \import{plots/}{J22-arndt-Procedure.pdf_tex}
    \caption{Prozedurale Volumenreduktion des Parameterraums im heuristischen Screening für \ac{L-DoE} (adaptiert nach \textcite{Arndt.2023c})}
    \label{fig:screening_procedure_volume}
\end{figure}
\section{Zusammenfassung}
Das in diesem Kapitel vorgestellte heuristische Screening schließt die methodische Lücke zwischen der qualitativen Systemanalyse und der quantitativen Versuchsplanung.
Durch die strukturierte Nutzung von Expertenwissen (z.B. mittels \ac{DSM} und erweiterten Ishikawa-Diagrammen) lässt sich die Anzahl der Versuchs-Faktoren $\sym{k}$ rational reduzieren, ohne relevante Interaktionen zu vernachlässigen.
Entscheidend ist dabei der vollzogene Perspektivwechsel von der Betrachtung der initialen Performance-Streuung hin zur Analyse der zeitabhängigen Degradation eines Performancemerkmals.
Dieses Vorgehen schafft die notwendige Voraussetzung für die Anwendbarkeit der in Kapitel~\ref{chap:ansatz} diskutierten effizienten Versuchspläne für Lebensdauererprobungen, da diese ihre Stärken erst bei einer begrenzten Anzahl an Faktoren ($\sym{k} \approx 3 \dots 5$) wirtschaftlich ausspielen.
Die methodische Vorarbeit des Screenings fungiert somit als zentraler Hebel für die Effizienz des gesamten Lebensdauerversuchs.